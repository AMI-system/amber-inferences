{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import json\n",
    "from boto3.s3.transfer import TransferConfig\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm, ListedColormap\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working directory\n",
    "os.chdir(os.path.expanduser('~/amber-inferences'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region='cri'\n",
    "country='costarica'\n",
    "download_dir=f'./data/qc_plots/{country}'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "inference_dir = os.path.abspath(f'./data/{country}_inferences/')\n",
    "\n",
    "#listdir recursively\n",
    "def listdir_recursive(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "\n",
    "# Get all csv files in the inference directory\n",
    "inference_csvs = list(listdir_recursive(inference_dir))\n",
    "inference_csvs = [c for c in inference_csvs if c.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inference_csvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and Data Wrangling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image(image_path, dir, df, ax, scaling_required=False, crop_to_highlight=None, buffer=5, subtitle=None):\n",
    "    df_image = df.loc[df['image_path'] == image_path, ]\n",
    "\n",
    "    img = plt.imread(f\"{dir}/{os.path.basename(image_path)}\")\n",
    "    image = Image.open(f\"{dir}/{os.path.basename(image_path)}\").convert(\"RGB\")\n",
    "    subp = ax.imshow(img, origin='lower')\n",
    "\n",
    "    for j, row in df_image.iterrows():\n",
    "        x_min = row['x_min'] -buffer\n",
    "        y_min = row['y_min'] -buffer\n",
    "        x_max = row['x_max'] +buffer\n",
    "        y_max = row['y_max'] +buffer\n",
    "\n",
    "        if scaling_required:\n",
    "            original_width, original_height = image.size\n",
    "            x_min = x_min *300 / original_width\n",
    "            y_min = y_min *300 / original_height\n",
    "            x_max = x_max *300 / original_width\n",
    "            y_max = y_max *300 / original_height\n",
    "\n",
    "        x = int(x_min)\n",
    "        y = int(y_min)\n",
    "        w = int(x_max - x_min)\n",
    "        h = int(y_max - y_min)\n",
    "\n",
    "        if (row['class_name'] == \"moth\") and ('Lepidoptera' not in row['order_name']):\n",
    "            col = 'orange'\n",
    "        elif (row['class_name'] != \"moth\") and ('Lepidoptera' in row['order_name']):\n",
    "            col = 'purple'\n",
    "        elif (row['class_name'] == \"moth\") and ('Lepidoptera' in row['order_name']):\n",
    "                col = 'green'\n",
    "        else:\n",
    "            col = 'red'\n",
    "\n",
    "        alph = 1\n",
    "        if crop_to_highlight is not None:\n",
    "            if row['crop_status'] != crop_to_highlight:\n",
    "                alph = 0.2\n",
    "\n",
    "\n",
    "        if (row['class_name'] == \"moth\") or (\"Lepidoptera\" in row['order_name']):\n",
    "            ax.text(x_min, y_max,\n",
    "                    f\"{row['top_1_species']}: {row['top_1_confidence']:.2f}\",\n",
    "                    color=col,\n",
    "                    fontsize=5, alpha=alph,\n",
    "                    verticalalignment=\"bottom\")\n",
    "\n",
    "        rect = plt.Rectangle((x, y), w, h, fill=False, edgecolor=col, linewidth=1, alpha=alph)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    if not subtitle:\n",
    "        subtitle=f\"{os.path.basename(image_path)}\"\n",
    "    ax.set_title(subtitle)\n",
    "    ax.axis('off')\n",
    "    return subp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(s3_client, config, key, download_dir, bucket_name):\n",
    "    download_path = os.path.join(download_dir, os.path.basename(key))\n",
    "    s3_client.download_file(bucket_name, key, download_path, Config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_session(credentials_file=\"credentials.json\"):\n",
    "    \"\"\"\n",
    "    Load AWS and API credentials from a configuration file and initialise an AWS session.\n",
    "\n",
    "    Args:\n",
    "        credentials_file (str): Path to the credentials JSON file.\n",
    "\n",
    "    Returns:\n",
    "        boto3.Client: Initialised S3 client.\n",
    "    \"\"\"\n",
    "    with open(credentials_file, encoding=\"utf-8\") as config_file:\n",
    "        aws_credentials = json.load(config_file)\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=aws_credentials[\"AWS_ACCESS_KEY_ID\"],\n",
    "        aws_secret_access_key=aws_credentials[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "        region_name=aws_credentials[\"AWS_REGION\"],\n",
    "    )\n",
    "    client = session.client(\"s3\", endpoint_url=aws_credentials[\"AWS_URL_ENDPOINT\"])\n",
    "    return client\n",
    "\n",
    "client = initialise_session('./credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer configuration for optimised S3 download\n",
    "transfer_config = TransferConfig(\n",
    "    max_concurrency=20,  # Increase the number of concurrent transfers\n",
    "    multipart_threshold=8 * 1024 * 1024,  # 8MB\n",
    "    max_io_queue=1000,\n",
    "    io_chunksize=262144,  # 256KB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moth_only_df(inference_csvs):\n",
    "    df = pd.DataFrame()\n",
    "    for c in tqdm(inference_csvs, desc='Reading in the csvs'):\n",
    "        input_df = pd.read_csv(c, low_memory=False)\n",
    "        input_df = input_df.loc[input_df['crop_status'] != 'NO DETECTIONS FOR IMAGE', ]\n",
    "        input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "\n",
    "        input_df = input_df.loc[input_df['top_1_species'].isna() == False, ]\n",
    "        input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "        input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "\n",
    "        # set new keys column as 'dep' and 'image_path' combined\n",
    "        input_df['keys'] = input_df['image_path'].apply(lambda x: f\"{input_df['dep'].iloc[0]}/snapshot_images/{os.path.basename(x)}\")\n",
    "        df = pd.concat([df, input_df])\n",
    "        del input_df\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_summary(inference_csvs, category='order_name'):\n",
    "    df = pd.DataFrame()\n",
    "    for c in inference_csvs:\n",
    "        input_df = pd.read_csv(c, low_memory=False)\n",
    "        input_df = input_df.loc[input_df['crop_status'] != 'NO DETECTIONS FOR IMAGE', ]\n",
    "        input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "\n",
    "        input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "        input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "\n",
    "        # summarise the order_name by deployment\n",
    "        summary = input_df[['dep', category]].value_counts()\n",
    "        summary = summary.reset_index()\n",
    "        summary.columns = ['deployment', category, 'count']\n",
    "        summary['file'] = os.path.basename(c)\n",
    "\n",
    "        df = pd.concat([df, summary], ignore_index=True)\n",
    "        del input_df\n",
    "\n",
    "    df = df[['deployment', category, 'count']].groupby(['deployment', category]).sum().reset_index()\n",
    "\n",
    "    df = df.sort_values(by=['deployment', 'count'], ascending=[True, False])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(file_name, format=\"%Y-%m-%d\"):\n",
    "    \"\"\"\n",
    "    Extracts the date from the file name based on the specified format.\n",
    "    Assuming the date is in the filename and formatted as YYYYMMDD or similar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_name = os.path.splitext(file_name)[0]\n",
    "        file_raw = os.path.basename(file_name).replace(\"_\", \"-\").split(\"-\")\n",
    "        file = [x for x in file_raw if x.startswith(\"202\")][0]\n",
    "\n",
    "        # catch for delim between date and time in file name\n",
    "        if len(file) < 12:\n",
    "            i0 = [idx for idx in range(len(file_raw)) if file_raw[idx].startswith(\"202\")][0]\n",
    "            file = ('').join(file_raw[i0:i0+2])\n",
    "\n",
    "        image_dt = datetime.strptime(file, \"%Y%m%d%H%M%S%f\")\n",
    "        image_dt = datetime.strftime(image_dt, format)\n",
    "        return image_dt\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error parsing date from file name {file_name}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def assign_night(ts, night_endpoint=12, night_startpoint=12):\n",
    "    \"\"\"\n",
    "    Defines the recording night from date and time.\n",
    "    The recording night cutoff is defined between night_startpoint on day 1\n",
    "    and night_endpoint day 2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if ts.time() < time(night_endpoint, 0):  # before night_endpoint o'clock\n",
    "            night_start = ts.date() - timedelta(days=1)\n",
    "        elif ts.time() >= time(night_startpoint, 0):  # after night_startpoint or later\n",
    "            night_start = ts.date()\n",
    "        else:\n",
    "            # times not included in this overnight window\n",
    "            night_start = pd.NaT\n",
    "        if pd.isna(night_start):\n",
    "            return None\n",
    "        night_end = night_start + timedelta(days=1)\n",
    "        return night_start\n",
    "    except Exception as e:\n",
    "        return 'No known date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dep_session_df_all\n",
    "end_date=None\n",
    "min_date=pd.to_datetime('2024-01-01')\n",
    "drop_empty_days = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2024-01-01').strftime('%b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_plot_data(df, drop_empty_days = True, min_date=pd.to_datetime('2024-01-01'), end_date=None):\n",
    "    df['session'] = pd.to_datetime(df['session'])\n",
    "\n",
    "    if end_date is None:\n",
    "        end_date = df['session'].max()\n",
    "\n",
    "    all_dates = pd.date_range(start=min_date, end=end_date)\n",
    "    df = df.set_index('session').reindex(all_dates).fillna(0).rename_axis('session').reset_index()\n",
    "\n",
    "    # Add week, day of week, and year\n",
    "    df['week'] = df['session'].dt.isocalendar().week\n",
    "    df['weekday'] = df['session'].dt.weekday  # Monday=0\n",
    "    df['month'] = df['session'].dt.month\n",
    "    df['year'] = df['session'].dt.year\n",
    "    df['week_number'] = ((df['session'] - min_date).dt.days // 7).astype(int)\n",
    "    df['week_label'] = 'W' + df['week_number'].astype(str)\n",
    "\n",
    "    # Some dates in last week of December may belong to week 1 of next year\n",
    "    df.loc[df['week'] == 1, 'year'] = df['session'].dt.year\n",
    "\n",
    "    # Pivot for heatmap\n",
    "    heatmap_data = df.pivot_table(index='weekday', columns='week_number', values='count', aggfunc='sum')\n",
    "\n",
    "    # Reorder to GitHub style\n",
    "    day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    heatmap_data.index = [day_names[i] for i in heatmap_data.index]\n",
    "    heatmap_data = heatmap_data.reindex(['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'])\n",
    "\n",
    "    # Determine month labels\n",
    "    year_labels = df.drop_duplicates('week_number').set_index('year').index\n",
    "    month_labels = df.drop_duplicates('week_number').set_index('session').index.strftime('%b')\n",
    "    week_labels = df.drop_duplicates('week_number').set_index('week_number').loc[heatmap_data.columns, 'week_label']\n",
    "\n",
    "\n",
    "    if drop_empty_days:\n",
    "        heatmap_data = heatmap_data.fillna(0)\n",
    "        heatmap_data = heatmap_data.loc[(heatmap_data != 0).any(axis=1)]\n",
    "        heatmap_data = heatmap_data.dropna(axis=0, how='all')\n",
    "\n",
    "    return [heatmap_data, month_labels, week_labels, year_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_plot(df, ax, dep, min_date=pd.to_datetime('2024-01-01'), vmin=0, vmax=1e6, custom_cmap='Greens', include_month_labels=True, end_date=None, label_buffer=1, show_colourbar=True):\n",
    "    heatmap_data, month_labels, week_labels, year_labels = activity_plot_data(df, drop_empty_days=True, min_date=min_date, end_date=end_date)\n",
    "    norm = LogNorm(vmin=vmin, vmax=vmax + 1)\n",
    "\n",
    "    c = ax.pcolor(heatmap_data.values, cmap=custom_cmap,\n",
    "                  edgecolors='grey', linewidths=1, norm=norm)\n",
    "\n",
    "    ax.set_yticks(np.arange(0.5, len(heatmap_data.index), 1))\n",
    "    ax.set_yticklabels(heatmap_data.index)\n",
    "\n",
    "    ax.set_xticks(np.arange(0.5, len(week_labels), 1))\n",
    "    ax.set_xticklabels(week_labels, rotation=90)\n",
    "\n",
    "    if include_month_labels:\n",
    "        for i, label in enumerate(month_labels):\n",
    "            if i > 0 and month_labels[i] != month_labels[i - 1]:\n",
    "                ax.text(i + 0.5, -2*label_buffer, label, ha='center', va='center')\n",
    "            elif i == 0:\n",
    "                ax.text(i + 0.5, -2*label_buffer, label, ha='center', va='center')\n",
    "\n",
    "        for i, label in enumerate(year_labels):\n",
    "            if i > 0 and year_labels[i] != year_labels[i - 1]:\n",
    "                ax.text(i + 0.5, -3*label_buffer, label, ha='center', va='center')\n",
    "            elif i == 0:\n",
    "                ax.text(i + 0.5, -3*label_buffer, label, ha='center', va='center')\n",
    "\n",
    "    if show_colourbar:\n",
    "        fig.colorbar(c, ax=ax, orientation='vertical', label='Number of crops')\n",
    "    ax.set_title(dep)\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot showing the correlation between order confidence and crop area\n",
    "\n",
    "# this plot takes a while to compile, uncomment if you want to run\n",
    "# sns.regplot(x=df['order_confidence'], y=df['crop_area'], logx=True, line_kws=dict(color=\"r\"))\n",
    "# plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df for deployment counts\n",
    "dep_session_df = pd.DataFrame()\n",
    "dep_session_df_moth = pd.DataFrame()\n",
    "for c in tqdm(inference_csvs, desc='reading in the csvs'):\n",
    "    input_df = pd.read_csv(c, low_memory=False)\n",
    "    input_df = input_df.loc[input_df['crop_status'] != 'NO DETECTIONS FOR IMAGE', ]\n",
    "    input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "\n",
    "    input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "    input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "    input_df['datetime'] = input_df['image_path'].apply(lambda x: get_date(x, format=\"%Y-%m-%d %H:%M:%S\"))\n",
    "    input_df['datetime'] = pd.to_datetime(input_df['datetime'])\n",
    "\n",
    "    # get the session night\n",
    "    input_df['session'] = input_df['datetime'].apply(assign_night)\n",
    "\n",
    "    # summarise the order_name by deployment\n",
    "    summary = input_df[['dep', 'session']].value_counts()\n",
    "    summary = summary.reset_index()\n",
    "    summary['file'] = os.path.basename(c)\n",
    "    dep_session_df = pd.concat([dep_session_df, summary], ignore_index=True)\n",
    "\n",
    "    # summarise the order_name by deployment\n",
    "    input_df = input_df.loc[input_df['order_name'].str.contains(\"Lepidoptera\"), ]\n",
    "    summary_moth = input_df[['dep', 'session']].value_counts()\n",
    "    summary_moth = summary_moth.reset_index()\n",
    "    summary_moth['file'] = os.path.basename(c)\n",
    "    dep_session_df_moth = pd.concat([dep_session_df_moth, summary_moth], ignore_index=True)\n",
    "\n",
    "    del input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_session_df = dep_session_df.loc[dep_session_df['session'] != 'No known date', ]\n",
    "dep_session_df = dep_session_df[['dep', 'count', 'session']].groupby(['dep', 'session']).sum().reset_index()\n",
    "dep_session_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_df = dep_session_df[['dep', 'count']].groupby(['dep']).sum().reset_index()\n",
    "dep_df = dep_df.sort_values(by=['dep', 'count'], ascending=[True, False])\n",
    "dep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_session_df_all = dep_session_df[['session', 'count']].groupby(['session']).sum().reset_index()\n",
    "dep_session_df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.Greens\n",
    "newcolors = cmap(np.linspace(0, 1, 256))\n",
    "newcolors[0] = [1, 1, 1, 1]  # RGBA for white\n",
    "custom_cmap = ListedColormap(newcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "activity_plot(dep_session_df_all, ax, dep='All', min_date=pd.to_datetime('2024-01-01'),\n",
    "              vmin=1, vmax=dep_session_df_all['count'].max(), custom_cmap=custom_cmap)\n",
    "\n",
    "ax.set_title(\"Crop Activity Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date=pd.to_datetime('2024-01-01')\n",
    "max_labels = ((pd.to_datetime(dep_session_df['session']).max() - min_date).days // 7)\n",
    "date_range = pd.date_range(start=min_date, end=pd.to_datetime(dep_session_df['session']).max(), freq='W')\n",
    "\n",
    "week_labels = ['W' + str(i+1) for i in range(len(date_range))]\n",
    "year_labels = [x.strftime('%Y') for x in date_range]\n",
    "month_labels = [x.strftime('%b') for x in date_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots with activity plots for each deployment\n",
    "ncols=1\n",
    "fig, axs = plt.subplots(6, ncols, figsize=(20, 10), sharex='all')\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, dep in enumerate(dep_df['dep'].unique()):\n",
    "    c=activity_plot(dep_session_df.loc[dep_session_df['dep'] == dep, ['dep', 'session', 'count']],\n",
    "                  axs[i], dep=dep, min_date=pd.to_datetime('2024-01-01'),\n",
    "                vmin=1, vmax=dep_session_df['count'].max(), label_buffer=2,\n",
    "                custom_cmap=custom_cmap, include_month_labels=False, end_date = dep_session_df['session'].max(),\n",
    "                show_colourbar=False)\n",
    "    axs[i].set_aspect('equal')\n",
    "\n",
    "axs[i].set_xticks(np.arange(0.5, len(week_labels), 1))\n",
    "axs[i].set_xticklabels(week_labels, rotation=90)\n",
    "axs[i-1].set_xticks(np.arange(0.5, len(week_labels), 1))\n",
    "axs[i-1].set_xticklabels(week_labels, rotation=90)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.25, -0.1*ncols, 0.5, 0.03])  # [left, bottom, width, height]\n",
    "fig.colorbar(c, cax=cbar_ax, orientation='horizontal', label='Crop count (log scale)')\n",
    "\n",
    "# Optional week index labels\n",
    "for i, label in enumerate(month_labels):\n",
    "    if i > 0 and month_labels[i] != month_labels[i - 1]:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -2*ncols, label, ha='center', va='center')\n",
    "    elif i == 0:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -2*ncols, label, ha='center', va='center')\n",
    "\n",
    "\n",
    "for i, label in enumerate(year_labels):\n",
    "    if i > 0 and year_labels[i] != year_labels[i - 1]:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -3*ncols, label, ha='center', va='center')\n",
    "    elif i == 0:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -3*ncols, label, ha='center', va='center')\n",
    "\n",
    "plt.suptitle(\"Crop Activity Heatmap\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=dep_df, hue='count', y='count', x='dep')\n",
    "plt.title('All crops per deployment')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.yscale('log')\n",
    "plt.legend().set_visible(False)\n",
    "plt.ylabel('Number of crops')\n",
    "plt.xlabel('Deployment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moth Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = moth_only_df(inference_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_path'].value_counts().plot(kind='hist', bins=100, figsize=(5, 3))\n",
    "plt.title('Moth crops per image')\n",
    "plt.xlabel('Number of moth crops per image (n > 0)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the confidence distribution for each deployment in subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 5), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, dep in enumerate(df['dep'].unique()):\n",
    "    ax = axes[i]\n",
    "    dep_df = df.loc[df['dep'] == dep, ]\n",
    "    dep_df['image_path'].value_counts().plot(kind='hist', bins=100, ax=ax)\n",
    "    ax.set_title(dep)\n",
    "    ax.set_xlabel('Number of moth crops per image (n > 0)')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "plt.suptitle(f'Confidence Distribution of 5 Most Likely Species Predictions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_counts = df['dep'].value_counts()\n",
    "dep_counts = dep_counts.reset_index()\n",
    "dep_counts.columns = ['deployment', 'count']\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=dep_counts, hue='count', y='count', x='deployment')\n",
    "plt.title('Moth crops per deployment')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.yscale('log')\n",
    "plt.legend(visible=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Prediction Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_counts = cat_summary(inference_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=order_counts, hue='deployment', y='count', x='order_name')\n",
    "plt.title('Counts by Deployment and Order')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Order')\n",
    "plt.ylabel('Number of Crops')\n",
    "plt.legend(title='Order Name', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species Prediction Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_counts = cat_summary(inference_csvs, category='top_1_species')\n",
    "\n",
    "# subset to only the top 10 species\n",
    "top_species = species_counts[['top_1_species', 'count']].groupby('top_1_species').sum().reset_index()\n",
    "top_species = top_species.sort_values(by='count', ascending=False)\n",
    "top_species = top_species.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=top_species, y='count', x='top_1_species')\n",
    "plt.title('Top Species Counts')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Most Likely Species')\n",
    "plt.ylabel('Number of Crops')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_species.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_counts['deployment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 7), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, dep in enumerate(species_counts['deployment'].unique()):\n",
    "    ax = axes[i]\n",
    "    dep_df = species_counts.loc[species_counts['deployment'] == dep, ]\n",
    "    dep_df = dep_df.sort_values(by='count', ascending=False).head(10)\n",
    "    sns.barplot(data=dep_df, y='count', x='top_1_species', ax=ax)\n",
    "    ax.set_title(dep)\n",
    "    ax.set_xticks(range(len(dep_df)))\n",
    "    ax.set_xticklabels(dep_df['top_1_species'], rotation=45, ha='right')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Number of Crops')\n",
    "\n",
    "plt.suptitle('Top Species Observations by Deployment')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=species_counts.loc[species_counts['top_1_species'].isin(top_species['top_1_species']), ], hue='deployment', y='count', x='top_1_species')\n",
    "plt.title('Top Species Counts by Deployment')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Most popular species', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Most Likely Species')\n",
    "plt.ylabel('Number of Crops')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['top_1_confidence'].plot(kind='hist', bins=50, figsize=(6, 3))\n",
    "df['top_2_confidence'].plot(kind='hist', bins=50, color='orange', alpha=0.5)\n",
    "df['top_3_confidence'].plot(kind='hist', bins=50, color='yellow', alpha=0.5)\n",
    "df['top_4_confidence'].plot(kind='hist', bins=50, color='green', alpha=0.5)\n",
    "df['top_5_confidence'].plot(kind='hist', bins=50, color='purple', alpha=0.5)\n",
    "\n",
    "plt.legend(['Top 1 Confidence', 'Top 2 Confidence', 'Top 3 Confidence', 'Top 4 Confidence', 'Top 5 Confidence'])\n",
    "plt.title('Confidence Distribution of 5 Most Likely Species Predictions')\n",
    "plt.xlabel('Confidence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the confidence distribution for each deployment in subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 5), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, dep in enumerate(df['dep'].unique()):\n",
    "    ax = axes[i]\n",
    "    dep_df = df.loc[df['dep'] == dep, ]\n",
    "    dep_df['top_1_confidence'].plot(kind='hist', bins=50, ax=ax, alpha=0.5)\n",
    "    dep_df['top_2_confidence'].plot(kind='hist', bins=50, ax=ax, color='orange', alpha=0.5)\n",
    "    dep_df['top_3_confidence'].plot(kind='hist', bins=50, ax=ax, color='yellow', alpha=0.5)\n",
    "    dep_df['top_4_confidence'].plot(kind='hist', bins=50, ax=ax, color='green', alpha=0.5)\n",
    "    dep_df['top_5_confidence'].plot(kind='hist', bins=50, ax=ax, color='purple', alpha=0.5)\n",
    "    ax.legend().set_visible(False)\n",
    "    ax.set_title(dep)\n",
    "    ax.set_xlabel('Confidence')\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "\n",
    "handles, _ = axes[0].get_legend_handles_labels()\n",
    "labels = ['Top 1 Confidence', 'Top 2 Confidence', 'Top 3 Confidence', 'Top 4 Confidence', 'Top 5 Confidence']\n",
    "fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.2, 0.9))\n",
    "plt.suptitle(f'Confidence Distribution of 5 Most Likely Species Predictions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Confident cases for each order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images required per order\n",
    "n_images = 1\n",
    "\n",
    "# create a df for the most confidence order predictions\n",
    "order_df = pd.DataFrame()\n",
    "for c in inference_csvs:\n",
    "    input_df = pd.read_csv(c, low_memory=False)\n",
    "    input_df = input_df.loc[input_df['crop_status'] != 'NO DETECTIONS FOR IMAGE', ]\n",
    "    input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "    input_df = input_df.sort_values(by='order_confidence', ascending=False)\n",
    "\n",
    "    input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "    input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "\n",
    "    # set new keys column as 'dep' and 'image_path' combined\n",
    "    input_df['keys'] = input_df['image_path'].apply(lambda x: f\"{input_df['dep'].iloc[0]}/snapshot_images/{os.path.basename(x)}\")\n",
    "    order_df = pd.concat([order_df, input_df])\n",
    "    del input_df\n",
    "\n",
    "order_df = order_df.sort_values(by=['dep', 'order_confidence'], ascending=[True, False])\n",
    "order_df = order_df.groupby(['order_name', 'dep']).head(n_images).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by confidence and subset\n",
    "df_order = order_df.sort_values(by='order_confidence', ascending=False)\n",
    "df_order = df_order.loc[df_order['order_confidence'] > 0.95, ]\n",
    "df_order.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df_order.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'order'), exist_ok=True)\n",
    "\n",
    "for i, row in df_order.iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'order'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(5, 6, figsize=(15, 7.5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_order = df_order.sort_values(by='order_name', ascending=False)\n",
    "\n",
    "# for eah row in df_confident, get the image_path\n",
    "for i, row in df_order.iterrows():\n",
    "    annotate_image(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'order'),\n",
    "        df_order,\n",
    "        ax[i],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"{row['dep']}\\n{row['order_name']}, {row['order_confidence']:.2f}\"\n",
    "    )\n",
    "\n",
    "for i in range(len(df_order), len(ax)):\n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Confident Species Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by top_1_confidence\n",
    "df_confident = df.sort_values(by='top_1_confidence', ascending=False)\n",
    "df_confident.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# remove duplicated rows by image path, and bounding box\n",
    "df_confident = df_confident.drop_duplicates(subset=['image_path', 'x_min', 'y_min', 'x_max', 'y_max'])\n",
    "df_confident = df_confident.drop_duplicates(subset=['top_1_species'])\n",
    "\n",
    "top_n=20\n",
    "\n",
    "df_confident = df_confident.head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by image_path\n",
    "df_confident.sort_values(by='image_path', inplace=True)\n",
    "df_confident.reset_index(drop=True, inplace=True)\n",
    "df_confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'confident'), exist_ok=True)\n",
    "\n",
    "for i, row in df_confident.head(top_n).iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'confident'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confident.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(4, 5, figsize=(13.33, 7.5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_confident = df_confident.sort_values(by='top_1_confidence', ascending=False)\n",
    "\n",
    "# for eah row in df_confident, get the image_path\n",
    "for i, row in df_confident.iterrows():\n",
    "    annotate_image(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'confident'),\n",
    "        df_confident,\n",
    "        ax[i],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"{row['top_1_species']}, ({row['top_1_confidence']:.2f})\"\n",
    "    )\n",
    "\n",
    "for i in range(len(df_confident), len(ax)):\n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Largest Moths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by moth size\n",
    "df_area = df.sort_values(by='crop_area', ascending=False)\n",
    "df_area.reset_index(drop=True, inplace=True)\n",
    "df_area = df_area.drop_duplicates(subset=['top_1_species'])\n",
    "df_area = df_area.loc[df_area['top_1_confidence'] > 0.85, ]\n",
    "\n",
    "top_n=20\n",
    "\n",
    "df_area = df_area.head(top_n)\n",
    "\n",
    "df_area.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'largest'), exist_ok=True)\n",
    "\n",
    "for i, row in df_area.iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'largest'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(4, 5, figsize=(13.33, 7.5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_area = df_area.sort_values(by='crop_area', ascending=False)\n",
    "\n",
    "# for eah row in df_confident, get the image_path\n",
    "for i, row in df_area.iterrows():\n",
    "    annotate_image(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'largest'),\n",
    "        df_area,\n",
    "        ax[i],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"{row['top_1_species']}, ({row['top_1_confidence']:.2f})\"\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blurriest Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by moth size\n",
    "df_blur = df.sort_values(by='crop_bluriness', ascending=False)\n",
    "df_blur.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_blur = df_blur.drop_duplicates(subset=['top_1_species'])\n",
    "top_n=20\n",
    "\n",
    "df_blur = df_blur.head(top_n)\n",
    "\n",
    "df_blur.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'blur'), exist_ok=True)\n",
    "\n",
    "for i, row in df_blur.iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'blur'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(4, 5, figsize=(13.33, 7.5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_blur = df_blur.sort_values(by='crop_bluriness', ascending=False)\n",
    "\n",
    "# for eah row in df_blur, get the image_path\n",
    "for i, row in df_blur.iterrows():\n",
    "    annotate_image(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'blur'),\n",
    "        df_blur,\n",
    "        ax[i],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"Crop blur: {float(row['crop_bluriness']):.3f}\\nImage blur: {float(row['image_bluriness']):.3f}\"\n",
    "\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bluriest Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by moth size\n",
    "df = df.astype({'image_bluriness': 'float'})\n",
    "df_blur = df.sort_values(by='image_bluriness', ascending=False)\n",
    "\n",
    "df_blur.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_blur = df_blur.drop_duplicates(subset=['top_1_species'])\n",
    "df_blur = df_blur.drop_duplicates(subset=['image_bluriness'])\n",
    "top_n=20\n",
    "\n",
    "df_blur = df_blur.head(top_n)\n",
    "\n",
    "df_blur.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'blur'), exist_ok=True)\n",
    "\n",
    "for i, row in df_blur.iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'blur'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(4, 5, figsize=(13.33, 7.5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_blur = df_blur.sort_values(by='crop_bluriness', ascending=False)\n",
    "\n",
    "# for eah row in df_blur, get the image_path\n",
    "for i, row in df_blur.iterrows():\n",
    "    annotate_image(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'blur'),\n",
    "        df_blur,\n",
    "        ax[i],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"Crop blur: {float(row['crop_bluriness']):.3f}\\nImage blur: {float(row['image_bluriness']):.3f}\"\n",
    "\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
