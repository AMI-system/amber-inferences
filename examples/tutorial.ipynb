{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "\n",
    "This tutorial runs you through the process of running inferences for a deployments in Costa Rica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package if required\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "import amber_inferences\n",
    "from amber_inferences.utils.config import load_credentials\n",
    "from amber_inferences.utils.api_utils import get_buckets, deployments_summary, get_deployments\n",
    "from amber_inferences.utils.custom_models import *\n",
    "from amber_inferences.utils.inference_scripts import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the wd\n",
    "os.chdir(os.path.normpath('amber-inferences'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data on the Object Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance for the object store\n",
    "aws_credentials = load_credentials('./credentials.json')\n",
    "session = boto3.Session(\n",
    "        aws_access_key_id=aws_credentials[\"AWS_ACCESS_KEY_ID\"],\n",
    "        aws_secret_access_key=aws_credentials[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "        region_name=aws_credentials[\"AWS_REGION\"],\n",
    "    )\n",
    "s3_client = session.client(\"s3\", endpoint_url=aws_credentials[\"AWS_URL_ENDPOINT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸš¨ Note: this feature has been taken down by Posit so the app is not currently available ðŸš¨**\n",
    "\n",
    "Look at the deployments available on the object store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deployments = get_deployments(aws_credentials['UKCEH_username'], aws_credentials['UKCEH_password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the buckets/countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_deployments = pd.DataFrame(all_deployments)\n",
    "# all_deployments[all_deployments['status'] == 'active']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick one, cri (Costa Rica) and check out the data attached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr_deployments = deployments_summary(\n",
    "#     aws_credentials,\n",
    "#     subset_countries=[\"Costa Rica\"],\n",
    "#     subset_deployments=[\"dep000035\", \"dep000036\"],\n",
    "#     include_image_count=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the files for a given deployment(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr_deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log the image keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amber_inferences.utils.key_utils import save_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes some time to commenting out to save time\n",
    "# save_keys(\n",
    "#     s3_client,\n",
    "#     bucket=\"cri\",\n",
    "#     deployment_id=\"dep000035\",\n",
    "#     output_file=\"./examples/example_keys/dep000035_keys.json\",\n",
    "#     subdir=\"snapshot_images\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the keys\n",
    "!head ./examples/example_keys/interesting_timelapse.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from amber_inferences.utils.inference_scripts import download_image_from_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the first image in the keys file and open\n",
    "with open('./examples/example_keys/interesting_timelapse.json') as f:\n",
    "    keys = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./examples/images/dep000035/interesting_timelapse/raw/', exist_ok=True)\n",
    "\n",
    "for i in range(len(keys)):\n",
    "    download_image_from_key(s3_client, keys[i], 'cri', './examples/images/dep000035/interesting_timelapse/raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/raw/')\n",
    "image_paths = [os.path.join('./examples/images/dep000035/interesting_timelapse/raw/', x) for x in image_paths]\n",
    "\n",
    "image_paths = [x for x in image_paths if x.endswith('.jpg')]\n",
    "\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the images in a 2x5 grid\n",
    "# fig, axs = plt.subplots(5, 6, figsize=(20, 20))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i, img_path in enumerate(image_paths):\n",
    "#     if os.path.exists( img_path):  # Ensure the file exists\n",
    "#         img = mpimg.imread(img_path)\n",
    "#         axs[i].imshow(img)\n",
    "#         axs[i].axis(\"off\")  # Hide axes for better visualization\n",
    "#         axs[i].set_title(f\"Image {i+1}\")\n",
    "#     else:\n",
    "#         axs[i].axis(\"off\")\n",
    "#         axs[i].set_title(\"Missing Image\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open images and convert to a sequence\n",
    "images = [Image.open(img) for img in image_paths]\n",
    "\n",
    "# Save as GIF\n",
    "os.makedirs('./examples/images/dep000035/interesting_timelapse/gifs', exist_ok=True)\n",
    "gif_path = \"./examples/images/dep000035/interesting_timelapse/gifs/raw_images.gif\"\n",
    "images[0].save(gif_path, save_all=True, append_images=images[1:], duration=500, loop=0)\n",
    "\n",
    "del images\n",
    "# display(Image.open(gif_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Object Detection on the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_models(\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    localisation_model_path='./models/v1_localizmodel_2021-08-17-12-06.pt',\n",
    "    binary_model_path='./models/moth-nonmoth-effv2b3_20220506_061527_30.pth',\n",
    "    order_model_path='./models/dhc_best_128.pth',\n",
    "    order_threshold_path='./models/thresholdsTestTrain.csv',\n",
    "    species_model_path='./models/turing-costarica_v03_resnet50_2024-06-04-16-17_state.pt',\n",
    "    species_labels='./models/03_costarica_data_category_map.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_annotation(image_path, img=None, boxes={}, scale=False, default_colour='grey'):\n",
    "    if img is None:\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for box in boxes:\n",
    "        x0 = float(box['x_min'])\n",
    "        y0 = float(box['y_min'])\n",
    "        x1 = float(box['x_max'])\n",
    "        y1 = float(box['y_max'])\n",
    "        if scale:\n",
    "            og_width, og_height = img.size\n",
    "            x0 = x0/300*og_width\n",
    "            y0 = y0/300*og_height\n",
    "            x1 = x1/300*og_width\n",
    "            y1 = y1/300*og_height\n",
    "        if 'ann_col' not in box.keys():\n",
    "            box['ann_col'] = default_colour\n",
    "        if 'label' not in box.keys():\n",
    "            box['label'] = ''\n",
    "\n",
    "        draw.rectangle([x0, y0, x1, y1], outline=box['ann_col'], width=3)\n",
    "        draw.text((x0, y0), box['label'], fill=box['ann_col'],\n",
    "                  font=ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", size=50) )\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "os.makedirs('./examples/images/dep000035/interesting_timelapse/annotated_boxes/', exist_ok=True)\n",
    "os.makedirs('./examples/images/crops/interesting_timelapse/', exist_ok=True)\n",
    "\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    crops = crop_image_only(\n",
    "        image_path=img_path,\n",
    "        bucket_name=\"cri\",\n",
    "        localisation_model=models['localisation_model'],\n",
    "        proc_device=torch.device(\"cuda:0\"),\n",
    "        csv_file=\"./examples/interesting_timelapse_crops.csv\",\n",
    "        save_crops=True,\n",
    "        box_threshold=0.95,\n",
    "        crop_dir=\"./examples/images/crops/interesting_timelapse\",\n",
    "        job_name=None,\n",
    "    )\n",
    "\n",
    "    boxes = []\n",
    "    for j, row in crops.iterrows():\n",
    "        boxes.append({\n",
    "            'x_min': row['x_min'],\n",
    "            'y_min': row['y_min'],\n",
    "            'x_max': row['x_max'],\n",
    "            'y_max': row['y_max'],\n",
    "            'label': '',\n",
    "            'ann_col': 'grey'\n",
    "        })\n",
    "    del crops\n",
    "    img = image_annotation(img_path, boxes=boxes)\n",
    "\n",
    "    # save the image\n",
    "    img.save(f'./examples/images/dep000035/interesting_timelapse/annotated_boxes/{os.path.basename(img_path)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(8, 4, figsize=(20, 30))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i, img in enumerate(imgs):\n",
    "#     axs[i].imshow(img)\n",
    "#     axs[i].axis('off')\n",
    "#     axs[i].set_title(f\"Image {i+1}\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open images and convert to a sequence\n",
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/annotated_boxes/')\n",
    "image_paths = [os.path.join('./examples/images/dep000035/interesting_timelapse/annotated_boxes/', x) for x in image_paths]\n",
    "images = [Image.open(img) for img in image_paths]\n",
    "\n",
    "# Save as GIF\n",
    "gif_path = \"./examples/images/dep000035/interesting_timelapse/gifs/object_detection_images.gif\"\n",
    "images[0].save(gif_path, save_all=True, append_images=images[1:], duration=500, loop=0)\n",
    "\n",
    "# # display(Image.open(gif_path))\n",
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatbug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_models(\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    localisation_model_path='./models/flat_bug_M.pt',\n",
    "    binary_model_path='./models/moth-nonmoth-effv2b3_20220506_061527_30.pth',\n",
    "    order_model_path='./models/dhc_best_128.pth',\n",
    "    order_threshold_path='./models/thresholdsTestTrain.csv',\n",
    "    species_model_path='./models/turing-costarica_v03_resnet50_2024-06-04-16-17_state.pt',\n",
    "    species_labels='./models/03_costarica_data_category_map.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs('./examples/images/dep000035/interesting_timelapse/annotated_boxes_flatbug/', exist_ok=True)\n",
    "os.makedirs('./examples/images/crops/interesting_timelapse_flatbug/', exist_ok=True)\n",
    "\n",
    "all_crops = []\n",
    "\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    crops = crop_image_only(\n",
    "        image_path=img_path,\n",
    "        bucket_name=\"cri\",\n",
    "        localisation_model=models['localisation_model'],\n",
    "        proc_device=torch.device(\"cuda:0\"),\n",
    "        csv_file=\"./examples/interesting_timelapse_flatbug.csv\",\n",
    "        save_crops=True,\n",
    "        box_threshold=0,\n",
    "        crop_dir=\"./examples/images/crops/interesting_timelapse_flatbug\",\n",
    "        job_name=None,\n",
    "    )\n",
    "    crops = crops.loc[crops['crop_status'] != 'NO DETECTIONS FOR IMAGE',]\n",
    "\n",
    "    all_crops = all_crops + [crops]\n",
    "    if crops.shape[0] > 0:\n",
    "        boxes = []\n",
    "        for j, row in crops.iterrows():\n",
    "            boxes.append({\n",
    "                'x_min': row['x_min'],\n",
    "                'y_min': row['y_min'],\n",
    "                'x_max': row['x_max'],\n",
    "                'y_max': row['y_max'],\n",
    "                'label': '',\n",
    "                'ann_col': 'grey'\n",
    "            })\n",
    "        del crops\n",
    "        img = image_annotation(img_path, boxes=boxes, scale=False)\n",
    "\n",
    "        # save the image\n",
    "        img.save(f'./examples/images/dep000035/interesting_timelapse/annotated_boxes_flatbug/{os.path.basename(img_path)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(8, 4, figsize=(20, 30))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i, img in enumerate(imgs):\n",
    "#     axs[i].imshow(img)\n",
    "#     axs[i].axis('off')\n",
    "#     axs[i].set_title(f\"Image {i+1}\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open images and convert to a sequence\n",
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/annotated_boxes_flatbug/')\n",
    "image_paths = [os.path.join('./examples/images/dep000035/interesting_timelapse/annotated_boxes_flatbug/', x) for x in image_paths]\n",
    "images = [Image.open(img) for img in image_paths]\n",
    "\n",
    "# Save as GIF\n",
    "gif_path = \"./examples/images/dep000035/interesting_timelapse/gifs/flatbug_detection_images.gif\"\n",
    "images[0].save(gif_path, save_all=True, append_images=images[1:], duration=500, loop=0)\n",
    "\n",
    "# display(Image.open(gif_path))\n",
    "del images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crops = pd.concat(all_crops)\n",
    "all_crops = all_crops.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./examples/images/dep000035/interesting_timelapse/annotated_boxes_binary/', exist_ok=True)\n",
    "\n",
    "transform_species = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((300, 300)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/raw/')\n",
    "image_paths = [os.path.abspath(os.path.join('./examples/images/dep000035/interesting_timelapse/raw/', x)) for x in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_path in enumerate(image_paths):\n",
    "    imge = Image.open(image_path).convert(\"RGB\")\n",
    "    original_image = imge.copy()\n",
    "    original_width, original_height = imge.size\n",
    "\n",
    "    crops_df = all_crops.loc[all_crops['image_path'] == image_path, ]\n",
    "    crops_df = crops_df.loc[crops_df['crop_status'] != 'NO DETECTIONS FOR IMAGE',]\n",
    "\n",
    "    if crops_df.shape[0] > 0:\n",
    "        boxes = []\n",
    "        for j, row in crops_df.iterrows():\n",
    "            ann_col='red'\n",
    "            cropped_image = original_image.crop((row['x_min'], row['y_min'], row['x_max'], row['y_max']))\n",
    "            cropped_tensor = transform_species(cropped_image).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "            binary_prediction = classify_box(cropped_tensor, models['classification_model'])\n",
    "            if binary_prediction[0] == 'moth':\n",
    "                ann_col='green'\n",
    "\n",
    "            boxes.append({\n",
    "                'x_min': row['x_min'],\n",
    "                'y_min': row['y_min'],\n",
    "                'x_max': row['x_max'],\n",
    "                'y_max': row['y_max'],\n",
    "                'label': binary_prediction[0],\n",
    "                'ann_col': ann_col\n",
    "            })\n",
    "\n",
    "        im = image_annotation(image_path, boxes=boxes, scale=False)\n",
    "        im.save(f'./examples/images/dep000035/interesting_timelapse/annotated_boxes_binary/{os.path.basename(image_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open images and convert to a sequence\n",
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/annotated_boxes_binary/')\n",
    "image_paths = [os.path.join('./examples/images/dep000035/interesting_timelapse/annotated_boxes_binary/', x) for x in image_paths]\n",
    "images = [Image.open(img) for img in image_paths]\n",
    "\n",
    "# Save as GIF\n",
    "gif_path = \"./examples/images/dep000035/interesting_timelapse/gifs/binary_images.gif\"\n",
    "images[0].save(gif_path, save_all=True, append_images=images[1:], duration=500, loop=0)\n",
    "\n",
    "# display(Image.open(gif_path))\n",
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crops['image_path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/raw/')\n",
    "image_paths = [os.path.abspath(os.path.join('./examples/images/dep000035/interesting_timelapse/raw/', x)) for x in image_paths]\n",
    "image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./examples/images/dep000035/interesting_timelapse/annotated_boxes_order/', exist_ok=True)\n",
    "\n",
    "imgs = []\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    imge = Image.open(image_path).convert(\"RGB\")\n",
    "    original_image = imge.copy()\n",
    "    original_width, original_height = imge.size\n",
    "\n",
    "    crops_df = all_crops.loc[all_crops['image_path'] == image_path, ]\n",
    "    crops_df = crops_df.loc[crops_df['crop_status'] != 'NO DETECTIONS FOR IMAGE',]\n",
    "\n",
    "    if crops_df.shape[0] > 0:\n",
    "        boxes = []\n",
    "        for j, row in crops_df.iterrows():\n",
    "            ann_col = 'red'\n",
    "            cropped_image = original_image.crop((row['x_min'], row['y_min'], row['x_max'], row['y_max']))\n",
    "            cropped_tensor = transform_species(cropped_image).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "            order_prediction = classify_order(\n",
    "                cropped_tensor,\n",
    "                models['order_model'],\n",
    "                models['order_model_labels'],\n",
    "                models['order_model_thresholds']\n",
    "            )\n",
    "            if 'Lepidoptera' in order_prediction[0]:\n",
    "                ann_col = 'green'\n",
    "\n",
    "            boxes.append({\n",
    "                'x_min': row['x_min'],\n",
    "                'y_min': row['y_min'],\n",
    "                'x_max': row['x_max'],\n",
    "                'y_max': row['y_max'],\n",
    "                'label': order_prediction[0],\n",
    "                'ann_col': ann_col\n",
    "            })\n",
    "\n",
    "        im = image_annotation(image_path, boxes=boxes, scale=False)\n",
    "        im.save(f'./examples/images/dep000035/interesting_timelapse/annotated_boxes_order/{os.path.basename(image_path)}')\n",
    "\n",
    "        imgs = imgs + [im]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open images and convert to a sequence\n",
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/annotated_boxes_order/')\n",
    "image_paths = [os.path.join('./examples/images/dep000035/interesting_timelapse/annotated_boxes_order/', x) for x in image_paths]\n",
    "images = [Image.open(img) for img in image_paths]\n",
    "\n",
    "# Save as GIF\n",
    "gif_path = \"./examples/images/dep000035/interesting_timelapse/gifs/order_images.gif\"\n",
    "images[0].save(gif_path, save_all=True, append_images=images[1:], duration=500, loop=0)\n",
    "\n",
    "# display(Image.open(gif_path))\n",
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/raw/')\n",
    "image_paths = [os.path.abspath(os.path.join('./examples/images/dep000035/interesting_timelapse/raw/', x)) for x in image_paths]\n",
    "\n",
    "# all_crops['image_path'] = all_crops['image_path'].replace('annotated_boxes', 'raw')\n",
    "\n",
    "print(image_paths[0])\n",
    "print(all_crops['image_path'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./examples/images/dep000035/interesting_timelapse/annotated_boxes_species/', exist_ok=True)\n",
    "\n",
    "imgs = []\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    imge = Image.open(image_path).convert(\"RGB\")\n",
    "    original_image = imge.copy()\n",
    "    original_width, original_height = imge.size\n",
    "\n",
    "    crops_df = all_crops.loc[all_crops['image_path'] == image_path, ]\n",
    "    crops_df = crops_df.loc[crops_df['crop_status'] != 'NO DETECTIONS FOR IMAGE',]\n",
    "\n",
    "    if crops_df.shape[0] > 0:\n",
    "        boxes = []\n",
    "        for j, row in crops_df.iterrows():\n",
    "            cropped_image = original_image.crop((row['x_min'], row['y_min'], row['x_max'], row['y_max']))\n",
    "            cropped_tensor = transform_species(cropped_image).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "            order_prediction = classify_order(\n",
    "                cropped_tensor,\n",
    "                models['order_model'],\n",
    "                models['order_model_labels'],\n",
    "                models['order_model_thresholds']\n",
    "            )\n",
    "            label = \"\"\n",
    "            ann_col = 'red'\n",
    "\n",
    "            if 'Lepidoptera' in order_prediction[0]:\n",
    "                species_names, species_confidences = classify_species(\n",
    "                    cropped_tensor,\n",
    "                    models['species_model'],\n",
    "                    models['species_model_labels'],\n",
    "                    5\n",
    "                )\n",
    "                label = f\"{species_names[0]}, {'%.2f'.format(species_confidences[0]*100)}%\"\n",
    "                ann_col='green'\n",
    "\n",
    "            boxes.append({\n",
    "                'x_min': row['x_min'],\n",
    "                'y_min': row['y_min'],\n",
    "                'x_max': row['x_max'],\n",
    "                'y_max': row['y_max'],\n",
    "                'label': label,\n",
    "                'ann_col': ann_col\n",
    "            })\n",
    "\n",
    "        im = image_annotation(image_path, boxes=boxes, scale=False)\n",
    "        im.save(f'./examples/images/dep000035/interesting_timelapse/annotated_boxes_species/{os.path.basename(image_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/annotated_boxes_species/')\n",
    "image_paths = [os.path.join('./examples/images/dep000035/interesting_timelapse/annotated_boxes_species/', x) for x in image_paths]\n",
    "print(len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open images and convert to a sequence\n",
    "image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/annotated_boxes_species/')\n",
    "image_paths = [os.path.join('./examples/images/dep000035/interesting_timelapse/annotated_boxes_species/', x) for x in image_paths]\n",
    "images = [Image.open(img) for img in image_paths]\n",
    "\n",
    "# Save as GIF\n",
    "gif_path = \"./examples/images/dep000035/interesting_timelapse/gifs/species_images.gif\"\n",
    "images[0].save(gif_path, save_all=True, append_images=images[1:], duration=500, loop=0)\n",
    "\n",
    "# display(Image.open(gif_path))\n",
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Pipeline from Command Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire pipeline can be run from the command line. The commands are shown below for demonstrative purposes using subprocess, but for high throughput analysis we recommend using slurm. There are examples of slurm scripts in the ./slurm_scripts directory: each regional bash file (e.g. `costarica_final.sh`) calls on the sbatch file `array_processor.sh`. \n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "chunk_id = 1\n",
    "batch_size = 20 # runs for 20 images at a time\n",
    "\n",
    "country='costarica'\n",
    "region=\"cri\"\n",
    "\n",
    "credentials_file=\"./credentials.json\"\n",
    "\n",
    "deployment_id = \"dep000035\"\n",
    "output_base_dir=f\"./data/{deployment_id}/{country}_test\"\n",
    "json_file = f\"./examples/example_keys/interesting_timelapse.json\"\n",
    "\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "os.makedirs(f\"{output_base_dir}/{deployment_id}\", exist_ok=True)\n",
    "\n",
    "species_model=\"./models/turing-costarica_v03_resnet50_2024-06-04-16-17_state.pt\"\n",
    "species_labels=\"./models/03_costarica_data_category_map.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_number_padded = f\"{chunk_id:04d}\"\n",
    "csv_file = f\"{output_base_dir}/{deployment_id}_{batch_number_padded}.csv\"\n",
    "print(f\"Results will save to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = [\n",
    "    \"python3\", \"-m\",\n",
    "    \"amber_inferences.cli.perform_inferences\",\n",
    "    \"--chunk_id\", str(chunk_id),\n",
    "    \"--batch_size\", str(batch_size),\n",
    "    \"--json_file\", json_file,\n",
    "    \"--output_dir\", output_base_dir,\n",
    "    \"--bucket_name\", region,\n",
    "    \"--credentials_file\", credentials_file,\n",
    "    \"--csv_file\", csv_file,\n",
    "    \"--species_model_path\", species_model,\n",
    "    \"--species_labels\", species_labels,\n",
    "    \"--perform_inference\",\n",
    "    \"--remove_image\",\n",
    "    \"--box_threshold\", \"0\",\n",
    "    \"--binary_model_path\", \"./models/moth-nonmoth-effv2b3_20220506_061527_30.pth\",\n",
    "    \"--localisation_model_path\", \"./models/flat_bug_M.pt\",\n",
    "    \"--order_model_path\", \"./models/dhc_best_128.pth\",\n",
    "    \"--order_thresholds_path\", \"./models/thresholdsTestTrain.csv\",\n",
    "    \"--skip_processed\",\n",
    "    \"--verbose\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "print(result.stdout)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"STDERR:\\n\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "import unittest\n",
    "from unittest.mock import patch, MagicMock\n",
    "from amber_inferences.utils.config import load_credentials\n",
    "from amber_inferences.utils.deployment_summary import count_files, print_deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setUp(self):\n",
    "        self.aws_credentials = load_credentials(\"./credentials.json\")\n",
    "\n",
    "mock_get_deployments = MagicMock()\n",
    "mock_get_deployments.return_value = [\n",
    "    {\"deployment_id\": \"dep000020\", \"location_name\": \"trap_4\", \"status\": \"active\", \"country\": \"Panama\", \"country_code\": \"pan\"},\n",
    "    {\"deployment_id\": \"dep000022\", \"location_name\": \"trap_6\", \"status\": \"inactive\", \"country\": \"Panama\", \"country_code\": \"pan\"},\n",
    "]\n",
    "\n",
    "# Mock count_files to return a specific number\n",
    "mock_count_files = MagicMock()\n",
    "mock_count_files.return_value = 0\n",
    "\n",
    "# Mock boto3 session and client\n",
    "mock_s3_client = MagicMock()\n",
    "mock_boto_session = MagicMock()\n",
    "mock_boto_session.return_value.client.return_value = mock_s3_client\n",
    "\n",
    "# Redirect stdout to capture print output\n",
    "captured_output = StringIO()\n",
    "sys.stdout = captured_output\n",
    "\n",
    "# Call the function\n",
    "print_deployments(self.aws_credentials, include_inactive=False, print_file_count=True)\n",
    "\n",
    "# Reset stdout\n",
    "# sys.stdout = sys.__stdout__\n",
    "\n",
    "# # Assert the captured output contains expected strings\n",
    "# output = captured_output.getvalue()\n",
    "# self.assertIn(\"Deployment ID: dep000020 - Location: trap_4\", output)\n",
    "# self.assertIn(\" - This deployment has 0 images.\", output)\n",
    "# self.assertNotIn(\"Deployment ID: fake_deployment - Location: fake_deployment\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_print_deployments_active_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = result['keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_count = len([x for x in keys if x.endswith(\".jpg\")])\n",
    "audio_count = len([x for x in keys if x.endswith(\".wav\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
