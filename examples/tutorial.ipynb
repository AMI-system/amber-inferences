{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "\n",
    "This tutorial runs you through the process of running inferences for a deployments in Costa Rica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/kgoldmann/Documents/Projects/AMBER/amber-inferences')\n",
    "os.system('pwd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package if required\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import amber_inferences\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from amber_inferences.utils.config import load_credentials\n",
    "from amber_inferences.utils.api_utils import get_buckets, deployments_summary, get_deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data on the Object Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance for the object store\n",
    "aws_credentials = load_credentials('./credentials.json')\n",
    "session = boto3.Session(\n",
    "        aws_access_key_id=aws_credentials[\"AWS_ACCESS_KEY_ID\"],\n",
    "        aws_secret_access_key=aws_credentials[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "        region_name=aws_credentials[\"AWS_REGION\"],\n",
    "    )\n",
    "s3_client = session.client(\"s3\", endpoint_url=aws_credentials[\"AWS_URL_ENDPOINT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the deployments available on the object store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deployments = get_deployments(aws_credentials['UKCEH_username'], aws_credentials['UKCEH_password'])\n",
    "\n",
    "all_deployments = pd.DataFrame(all_deployments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the buckets/countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deployments[all_deployments['status'] == 'active']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick one, cri (Costa Rica) and check out the data attached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_deployments = deployments_summary(\n",
    "    aws_credentials,\n",
    "    subset_countries=[\"Costa Rica\"],\n",
    "    subset_deployments=[\"dep000031\", \"dep000032\"],\n",
    "    include_image_count=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the files for a given deployment(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log the image keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amber_inferences.utils.key_utils import save_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes some time to commenting out to save time\n",
    "# save_keys(\n",
    "#     s3_client,\n",
    "#     bucket=\"cri\",\n",
    "#     deployment_id=\"dep000031\",\n",
    "#     output_file=\"./examples/dep000031_keys.json\",\n",
    "#     subdir=\"snapshot_images\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the keys\n",
    "!head ./examples/dep000031_keys.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from amber_inferences.utils.inference_scripts import download_image_from_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the first image in the keys file and open\n",
    "with open('./examples/dep000031_keys.json') as f:\n",
    "    keys = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100, 110):\n",
    "    download_image_from_key(s3_client, keys[i], 'cri', './examples/images/dep000031/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = os.listdir('./examples/images/dep000031/')\n",
    "image_paths = [os.path.join('./examples/images/dep000031/', x) for x in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the images in a 2x5 grid\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    if os.path.exists( img_path):  # Ensure the file exists\n",
    "        img = mpimg.imread(img_path)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis(\"off\")  # Hide axes for better visualization\n",
    "        axs[i].set_title(f\"Image {i+1}\")\n",
    "    else:\n",
    "        axs[i].axis(\"off\")\n",
    "        axs[i].set_title(\"Missing Image\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Object Detection on the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amber_inferences.utils.custom_models import *\n",
    "from amber_inferences.utils.inference_scripts import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_models(\n",
    "    device=torch.device(\"cpu\"),\n",
    "    localisation_model_path='./models/v1_localizmodel_2021-08-17-12-06.pt',\n",
    "    binary_model_path='./models/moth-nonmoth-effv2b3_20220506_061527_30.pth',\n",
    "    order_model_path='./models/dhc_best_128.pth',\n",
    "    order_threshold_path='./models/thresholdsTestTrain.csv',\n",
    "    species_model_path='./models/turing-costarica_v03_resnet50_2024-06-04-16-17_state.pt',\n",
    "    species_labels='./models/03_costarica_data_category_map.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = crop_image_only(\n",
    "    image_path='./examples/images/dep000031/01-20240131213830-snapshot.jpg',\n",
    "    bucket_name=\"cri\",\n",
    "    localisation_model=models['localisation_model'],\n",
    "    proc_device=torch.device(\"cpu\"),\n",
    "    csv_file=\"./examples/dep000031_crops.csv\",\n",
    "    save_crops=True,\n",
    "    box_threshold=0.99,\n",
    "    crop_dir=\"./examples/crops/dep000031\",\n",
    "    job_name=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annotate the input image with the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate the image with the bounding boxes\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "def image_annotation(image_path, img=None, boxes={}):\n",
    "    if img is None:\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for box in boxes:\n",
    "        x0 = box['x_min']\n",
    "        y0 = box['y_min']\n",
    "        x1 = box['x_max']\n",
    "        y1 = box['y_max']\n",
    "        draw.rectangle([x0, y0, x1, y1], outline='red', width=3)\n",
    "\n",
    "        if 'label' in box.keys():\n",
    "            draw.text((x0, y0), box['label'], fill='red')\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/kgoldmann/Documents/Projects/AMBER/amber-inferences/examples/images/dep000031/01-20240131213830-snapshot.jpg'\n",
    "crops_df = crops.loc[crops['image_path'] == image_path]\n",
    "\n",
    "# create a dict of the bounding boxes\n",
    "boxes = []\n",
    "for i, row in crops_df.iterrows():\n",
    "    boxes.append({\n",
    "        'x_min': row['x_min'],\n",
    "        'y_min': row['y_min'],\n",
    "        'x_max': row['x_max'],\n",
    "        'y_max': row['y_max']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_annotation(image_path, boxes=boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the crop\n",
    "transform_species = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((300, 300)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "original_image = image.copy()\n",
    "original_width, original_height = image.size\n",
    "\n",
    "crops_df = crops.loc[crops['image_path'] == image_path]\n",
    "x_min, y_min, x_max, y_max = crops_df.iloc[0][['x_min', 'y_min', 'x_max', 'y_max']]\n",
    "\n",
    "cropped_image = original_image.crop((x_min, y_min, x_max, y_max))\n",
    "cropped_tensor = transform_species(cropped_image).unsqueeze(0).to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_prediction = classify_box(cropped_tensor, models['classification_model'])\n",
    "\n",
    "print(f'Crop predicted to be {binary_prediction[0]} with {\"{:.2f}\".format(binary_prediction[1]*100)}% accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_prediction = classify_order(\n",
    "    cropped_tensor,\n",
    "    models['order_model'],\n",
    "    models['order_model_labels'],\n",
    "    models['order_model_thresholds']\n",
    ")\n",
    "\n",
    "print(f'Crop predicted to be {order_prediction[0]} with {\"{:.2f}\".format(order_prediction[1]*100)}% accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_names, species_confidences = classify_species(\n",
    "    cropped_tensor,\n",
    "    models['species_model'],\n",
    "    models['species_model_labels'],\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame({'species':species_names, 'confidence':species_confidences})\n",
    "\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from amber_inferences.utils.image_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_grid(local_image, prediction_df):\n",
    "    \"\"\"Displays a 2x3 grid with a local image + 5 images from GBIF.\"\"\"\n",
    "\n",
    "    # Create 2x3 plot grid\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 7))\n",
    "\n",
    "    # Display local image in top-left\n",
    "    axes[0, 0].imshow(local_image)\n",
    "    axes[0, 0].set_title(\"Crop Image\")\n",
    "    axes[0, 0].axis(\"off\")\n",
    "\n",
    "    # Fetch and display GBIF images\n",
    "    for i, sp in enumerate(prediction_df['species']):\n",
    "        row, col = divmod(i + 1, 3)  # Skip first slot (0,0) for crop image\n",
    "        img = get_gbif_image(sp)\n",
    "\n",
    "        if img:\n",
    "            axes[row, col].imshow(img)\n",
    "        else:\n",
    "            axes[row, col].text(0.5, 0.5, \"No Image\", ha=\"center\", va=\"center\")\n",
    "\n",
    "        axes[row, col].set_title(f\"{sp}, Liklihood: {prediction_df['confidence'][i]:.2f}\")\n",
    "        axes[row, col].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "display_images_grid(cropped_image, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
