{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d84600",
   "metadata": {},
   "source": [
    "# Across Country Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab0da5f",
   "metadata": {},
   "source": [
    "Plots: \n",
    "- Latitude\n",
    "  - vs crop size\n",
    "  - vs activity\n",
    "- Activity through the season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dde390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amber_inferences.utils.config import load_credentials\n",
    "from amber_inferences.utils.deployment_summary import deployment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5adb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_csvs = []\n",
    "\n",
    "for root, dirs, files in os.walk(os.path.abspath(f'/gws/ssde/j25b/ceh_generic/kgoldmann/')):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv') and 'compute' not in file and 'gpu' not in file and 'inferences_tracking' in root:\n",
    "            inference_csvs.append(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7dcc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inference_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir=f'./data/qc_plots/all'\n",
    "plot_dir = f'./sandbox/plots/all'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "os.makedirs(plot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modern Web Design Color Palette\n",
    "# Define web-optimized colors for better accessibility and modern design\n",
    "\n",
    "web_colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#7209B7',\n",
    "            '#2F9B69', '#dbb037','#a8dadc', '#264653']\n",
    "\n",
    "web_colors = {\n",
    "    'primary': web_colors[0],\n",
    "    'secondary': web_colors[1],\n",
    "    'accent1': web_colors[2],\n",
    "    'accent2': web_colors[3],\n",
    "    'accent3': web_colors[4],\n",
    "    'accent4': web_colors[5],\n",
    "    'accent5': web_colors[6],\n",
    "    'accent6': web_colors[7],\n",
    "    'text': web_colors[8],\n",
    "    'background': '#f5f5f5'  # Light background\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Create matplotlib-compatible color list\n",
    "modern_palette = [web_colors['primary'], web_colors['secondary'], web_colors['accent1'],\n",
    "                  web_colors['accent2'], web_colors['accent3'], web_colors['accent4'],\n",
    "                  web_colors['accent5'], web_colors['accent6']]\n",
    "\n",
    "# Set as default seaborn palette\n",
    "sns.set_palette(modern_palette)\n",
    "\n",
    "# display the colors with names underneath\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i, (name, color) in enumerate(web_colors.items()):\n",
    "    plt.fill_between([i, i + 1], 0, 1, color=color)\n",
    "    plt.text(i + 0.5, -0.1, name, ha='center', va='top', fontsize=10)\n",
    "plt.xlim(0, len(web_colors))\n",
    "plt.ylim(-0.2, 1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a colour map so Anguilla is primary, Costa Rica is secondary, Kenya is accent 2, Singapore is accent 5, and Thailand is accent 5\n",
    "country_map = {\n",
    "    'Anguilla': web_colors['primary'],\n",
    "    'Costa Rica': web_colors['secondary'],\n",
    "    'costarica': web_colors['secondary'],\n",
    "    'Kenya': web_colors['accent2'],\n",
    "    'Singapore': web_colors['accent5'],\n",
    "    'Thailand': web_colors['accent6']\n",
    "}\n",
    "\n",
    "\n",
    "bucket_names = {\n",
    "    'anguilla': 'aia',\n",
    "    'Costa Rica': 'cri',\n",
    "    'costarica': 'cri',\n",
    "    'kenya': 'ken',\n",
    "    'singapore': 'sgp',\n",
    "    'thailand': 'tha'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c792a",
   "metadata": {},
   "source": [
    "# General Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff17974e",
   "metadata": {},
   "source": [
    "## Number of crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99257bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique image paths per country and deployment\n",
    "def count_unique_images_per_country_dep(inference_csvs):\n",
    "    \"\"\"\n",
    "    Read all inference CSVs and count unique image paths per country and deployment.\n",
    "    Returns a DataFrame with columns: country, dep, unique_image_count\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for c in tqdm(inference_csvs, desc='Counting unique images per country/deployment'):\n",
    "        try:\n",
    "\n",
    "\n",
    "            # Read the full dataset with appropriate columns\n",
    "            df = pd.read_csv(c, usecols= ['image_path'], low_memory=False, on_bad_lines='skip')\n",
    "\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            # Extract deployment and country from file path\n",
    "            country = os.path.dirname(c).split('/')[-2].replace('_inferences_tracking', '')\n",
    "\n",
    "            # Count unique image paths for this CSV\n",
    "            unique_images = df['image_path'].nunique()\n",
    "\n",
    "\n",
    "\n",
    "            dep = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "\n",
    "            results.append({\n",
    "                'country': country,\n",
    "                'dep': dep,\n",
    "                'unique_image_count': unique_images,\n",
    "                'csv_file': os.path.basename(c)\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" - Error reading {c}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if not results_df.empty:\n",
    "        # Sort by country then by deployment\n",
    "        results_df = results_df.sort_values(['country', 'dep']).reset_index(drop=True)\n",
    "\n",
    "        # Add summary statistics\n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"Total countries: {results_df['country'].nunique()}\")\n",
    "        print(f\"Total deployments: {results_df['dep'].nunique()}\")\n",
    "        print(f\"Total unique images across all deployments: {results_df['unique_image_count'].sum():,}\")\n",
    "\n",
    "        # Show summary by country\n",
    "        country_summary = results_df.groupby('country').agg({\n",
    "            'dep': 'nunique',\n",
    "            'unique_image_count': 'sum'\n",
    "        }).rename(columns={'dep': 'num_deployments', 'unique_image_count': 'total_images'})\n",
    "\n",
    "        print(f\"\\nImages per country:\")\n",
    "        print(country_summary.to_string())\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dfbf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the function to get unique image counts\n",
    "image_counts_df = count_unique_images_per_country_dep(inference_csvs)\n",
    "image_counts_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6524b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get deployment names for the image counts data\n",
    "credentials = load_credentials(\"../credentials.json\")\n",
    "def get_deployment_names_for_images(image_counts_df):\n",
    "    \"\"\"\n",
    "    Get deployment names for the image counts data using the same approach as moth_df\n",
    "    \"\"\"\n",
    "    deployment_info = []\n",
    "\n",
    "    for bucket_name in image_counts_df['country'].unique():\n",
    "        print(f\"Processing {bucket_name}\")\n",
    "        deps = image_counts_df.loc[image_counts_df['country'] == bucket_name, 'dep'].unique()\n",
    "\n",
    "        print(f\" - Deployment: {deps}\")\n",
    "\n",
    "        # Get deployment data\n",
    "        try:\n",
    "            dep_data = deployment_data(\n",
    "                credentials,\n",
    "                subset_countries=[bucket_names[bucket_name]],\n",
    "                subset_deployments=list(deps),  # Convert to list\n",
    "                include_file_count=False,\n",
    "            )\n",
    "            # If dep_data is a list of dictionaries, extend the list\n",
    "            if isinstance(dep_data, list):\n",
    "                deployment_info.extend(dep_data)\n",
    "            else:\n",
    "                deployment_info.append(dep_data)\n",
    "        except Exception as e:\n",
    "            print(f\" - Error fetching deployment data for {deps}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Convert deployment info to DataFrame\n",
    "    deployment_df = pd.DataFrame()\n",
    "    for i in range(len(deployment_info)):\n",
    "        sub_dict = deployment_info[i]\n",
    "        dep_df = pd.DataFrame.from_dict(sub_dict, orient='index')\n",
    "        deployment_df = pd.concat([deployment_df, dep_df], ignore_index=True)\n",
    "\n",
    "    deployment_df = deployment_df.reset_index(drop=True)\n",
    "\n",
    "    # Merge with image counts data\n",
    "    image_counts_with_names = image_counts_df.merge(\n",
    "        deployment_df,\n",
    "        left_on='dep',\n",
    "        right_on='deployment_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    image_counts_with_names.columns = image_counts_with_names.columns.str.replace('_x', '')\n",
    "\n",
    "    return image_counts_with_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get deployment names\n",
    "image_counts_with_names = get_deployment_names_for_images(image_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920aff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualization of image counts by country and deployment\n",
    "def plot_image_counts_by_country_dep(df, save_fig=False):\n",
    "    \"\"\"\n",
    "    Create a bar plot showing unique image counts per deployment by country.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data to plot\")\n",
    "        return\n",
    "\n",
    "    # Set up the plot style\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(modern_palette)\n",
    "\n",
    "    # Clean country names\n",
    "    df = df.copy()\n",
    "    df['country'] = df['country'].str.replace('rica', ' rica').str.title()\n",
    "\n",
    "    # Sort by country and image count for better visualization\n",
    "    # df = df.sort_values(['country', 'unique_image_count'], ascending=[True, False])\n",
    "\n",
    "    # Create consistent country-color mapping\n",
    "    all_countries = sorted(df['country'].unique())\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), dpi=300)\n",
    "\n",
    "    # Create the bar plot\n",
    "    sns.barplot(\n",
    "        data=df,\n",
    "        x=\"location_name\",\n",
    "        y=\"unique_image_count\",\n",
    "        hue=\"country\",\n",
    "        palette=country_map,\n",
    "        dodge=False,\n",
    "        ax=ax,\n",
    "        alpha=0.8,\n",
    "        errorbar=None\n",
    "    )\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(\"Deployment\", fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(\"Number of Images\", fontsize=14, fontweight='bold')\n",
    "    ax.set_title(\"Number of Images Processed by Deployment and Country\",\n",
    "                fontsize=16, fontweight='bold', color=web_colors['text'], pad=20)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=10)\n",
    "\n",
    "    # Format y-axis with commas\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))\n",
    "\n",
    "    # Customize legend\n",
    "    legend = ax.legend(\n",
    "        title='Country',\n",
    "        title_fontsize=12,\n",
    "        fontsize=10,\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(1, 0.5),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True\n",
    "    )\n",
    "    legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "    # Add grid and styling\n",
    "    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_facecolor(web_colors['background'])\n",
    "    sns.despine()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig('images_processed.png', dpi=300, bbox_inches='tight',\n",
    "                   facecolor='white', edgecolor='none')\n",
    "\n",
    "# Plot the results\n",
    "plot_image_counts_by_country_dep(image_counts_with_names, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ade35a",
   "metadata": {},
   "source": [
    "# Number of Crops and Moths by Deployment and Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c272f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_df(inference_csvs):\n",
    "    complete_df = pd.DataFrame()\n",
    "    for c in tqdm(inference_csvs, desc='reading in the csvs'):\n",
    "        try:\n",
    "            input_df = pd.read_csv(c, low_memory=False, on_bad_lines='skip')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" - Error reading {c}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            input_df = input_df.loc[input_df['crop_status'] != 'No detections for this image.', ]\n",
    "            input_df = input_df.loc[input_df['crop_status'] != 'Image corrupt', ]\n",
    "\n",
    "            if input_df.shape[0] == 0:\n",
    "                # print(f\"  - No detections in {os.path.basename(c)}\")\n",
    "                continue\n",
    "            input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "\n",
    "            input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "\n",
    "            input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "\n",
    "\n",
    "            input_df['country'] = os.path.dirname(c).split('/')[-2].replace('_inferences_tracking', '')\n",
    "\n",
    "            complete_df = pd.concat([complete_df, input_df[['dep',  'crop_area', 'order_name', 'country']]], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\" - Error processing {c}: {e}\")\n",
    "            continue\n",
    "        del input_df\n",
    "\n",
    "    complete_df = complete_df.reset_index(drop=True)\n",
    "    return complete_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "moth_df = create_input_df(inference_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "moth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d247fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get deployment names for moth_df\n",
    "moth_df_with_names = get_deployment_names_for_images(moth_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "moth_df_with_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca833ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_by_country_dep(df, save_fig=False, plot_width=15, subset=False):\n",
    "    \"\"\"\n",
    "    Create publication-ready plot showing file counts per deployment by country for a specific data type.\n",
    "    \"\"\"\n",
    "    # Set publication-quality style with modern web colors\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(modern_palette)  # Use modern web palette\n",
    "\n",
    "    df['country'] = df['country'].str.replace('rica', ' rica').str.title()\n",
    "\n",
    "    sub_str = 'Crop'\n",
    "    if subset:\n",
    "        df = df.loc[(df['order_name'].str.contains('Lepidoptera'))]\n",
    "        sub_str='Moth'\n",
    "\n",
    "\n",
    "    # get the number of rows per deployment and country\n",
    "    df2 = df.groupby(['location_name', 'country']).size().reset_index(name='count')\n",
    "    df2 = df2.rename(columns={'country': 'Country'})\n",
    "\n",
    "    # Sort by country then count for better visual organization\n",
    "    df2 = df2.sort_values(by=['Country', 'count'], ascending=[True, False])\n",
    "\n",
    "    # Create consistent country-color mapping\n",
    "    all_countries = sorted(df2['Country'].unique())  # Get all countries from full dataset\n",
    "    country_color_map = {country: modern_palette[i % len(modern_palette)]\n",
    "                        for i, country in enumerate(all_countries)}\n",
    "\n",
    "    # Create figure with specific size for publication\n",
    "    fig, ax = plt.subplots(figsize=(plot_width, 6), dpi=300)\n",
    "\n",
    "    # Create the bar plot with modern web styling and consistent country colors\n",
    "    sns.barplot(\n",
    "        data=df2,\n",
    "        x=\"location_name\",\n",
    "        y=\"count\",\n",
    "        hue=\"Country\",\n",
    "        palette=country_map,  # Use consistent country-color mapping\n",
    "        dodge=False,  # No dodging needed since we're coloring by country\n",
    "        ax=ax,\n",
    "        alpha=0.8  # Slight transparency for elegance\n",
    "    )\n",
    "\n",
    "    # Customize the plot for publication quality\n",
    "    ax.set_xlabel(\"Deployment\", fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(f\"Number of {sub_str}s\", fontsize=14, fontweight='bold')\n",
    "    ax.set_title(f\"{sub_str} Counts by Deployment and Country\",\n",
    "                fontsize=16, fontweight='bold', color=web_colors['text'], pad=20)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=10)\n",
    "\n",
    "    # Improve y-axis\n",
    "    ax.tick_params(axis='y', labelsize=11)\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))\n",
    "\n",
    "    # Customize legend\n",
    "    legend = ax.legend(\n",
    "        title='Country',\n",
    "        title_fontsize=12,\n",
    "        fontsize=10,\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(1, 0.5),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True\n",
    "    )\n",
    "    legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "    # Add grid for better readability\n",
    "    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    sns.despine() # Remove top and right spines\n",
    "    plt.tight_layout(pad=2.0)\n",
    "\n",
    "\n",
    "    ax.set_facecolor(web_colors['background'])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(f'{sub_str}_counts_by_deployment.png', dpi=300, bbox_inches='tight',\n",
    "                   facecolor='white', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3994b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of rows per deployment and country\n",
    "counts_by_country_dep(moth_df_with_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59503bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_country_dep(moth_df_with_names, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31263688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dd503fc",
   "metadata": {},
   "source": [
    "# Latitude Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf839a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.DataFrame()\n",
    "for i in range(len(deployment_info)):\n",
    "    sub_dict = deployment_info[i]\n",
    "    dep_df = pd.DataFrame.from_dict(sub_dict, orient='index')\n",
    "    all_df = pd.concat([all_df, dep_df], ignore_index=True)\n",
    "\n",
    "all_df = all_df.reset_index(drop=True)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match moth_df with deployment_info\n",
    "moth_df = moth_df.merge(all_df, left_on='dep', how='left', right_on='deployment_id')\n",
    "moth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to order_name containing 'Lepidoptera'\n",
    "moth_sub = moth_df[moth_df['order_name'].str.contains('Lepidoptera', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "moth_sub['country'] = moth_sub['country_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93183797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a violin plot of latitude vs crop_area, subplot by country\n",
    "# Set up a nice color palette\n",
    "colors = sns.color_palette(\"Set2\", n_colors=len(moth_sub['country'].unique()))\n",
    "country_colors = dict(zip(sorted(moth_sub['country'].unique()), colors))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12), sharey=True)\n",
    "fig.patch.set_facecolor('white')\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (country, group) in enumerate(moth_sub.groupby('country')):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Create violin plot with custom styling\n",
    "    parts = ax.violinplot([group[group['dep'] == dep]['crop_area'].values\n",
    "                          for dep in sorted(group['dep'].unique())],\n",
    "                         positions=range(len(group['dep'].unique())),\n",
    "                         showmeans=True, showmedians=True)\n",
    "\n",
    "    # Style the violin plot\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(country_colors[country])\n",
    "        pc.set_alpha(0.7)\n",
    "        pc.set_edgecolor('darkgray')\n",
    "        pc.set_linewidth(1)\n",
    "\n",
    "    # Style the statistical lines\n",
    "    parts['cmeans'].set_color('red')\n",
    "    parts['cmeans'].set_linewidth(2)\n",
    "    parts['cmedians'].set_color('darkblue')\n",
    "    parts['cmedians'].set_linewidth(2)\n",
    "    parts['cbars'].set_color('black')\n",
    "    parts['cmins'].set_color('black')\n",
    "    parts['cmaxes'].set_color('black')\n",
    "\n",
    "    # Customize the axis\n",
    "    ax.set_title(country.title(), fontsize=14, fontweight='bold',\n",
    "                color=country_colors[country], pad=20)\n",
    "    ax.set_xlabel('Deployment', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Crop Area (pixels²)' if i % 3 == 0 else '', fontsize=12, fontweight='bold')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    # Set x-axis labels\n",
    "    ax.set_xticks(range(len(group['dep'].unique())))\n",
    "    ax.set_xticklabels(sorted(group['dep'].unique()), rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "    # Add subtle grid\n",
    "    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "    ax.set_facecolor('#fafafa')\n",
    "\n",
    "    # Add border\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('gray')\n",
    "        spine.set_linewidth(1.2)\n",
    "\n",
    "# Style remaining empty plots\n",
    "for ax in axes[len(moth_sub['country'].unique()):]:\n",
    "    ax.set_facecolor('white')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.grid(False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Crop Area Distribution of Lepidoptera by Deployment and Country',\n",
    "             fontsize=18, fontweight='bold', y=0.98, color='darkslategray')\n",
    "\n",
    "# Add a subtle background color to the figure\n",
    "fig.patch.set_facecolor('#f8f9fa')\n",
    "\n",
    "plt.savefig(os.path.join(plot_dir, 'crop_area_vs_deployment_by_country.png'),\n",
    "            dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number of detections per night, by deployment\n",
    "avg_detections = moth_df.groupby(['dep', 'country_x']).size().reset_index(name='detections')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24feac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "moth_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "moth_df['order_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac8dba",
   "metadata": {},
   "source": [
    "## Seasonal Activity Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_pop(inference_csvs):\n",
    "    complete_df = pd.DataFrame()\n",
    "    for c in tqdm(inference_csvs, desc='reading in the csvs'):\n",
    "        try:\n",
    "            input_df = pd.read_csv(c, low_memory=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" - Error reading {c}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            input_df = input_df.loc[input_df['crop_status'] != 'No detections for this image.', ]\n",
    "            input_df = input_df.loc[input_df['crop_status'] != 'Image corrupt', ]\n",
    "\n",
    "            if input_df.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            if input_df.shape[0] == 0:\n",
    "                # print(f\"  - No detections in {os.path.basename(c)}\")\n",
    "                continue\n",
    "            input_df = input_df.drop_duplicates(subset=['image_path', 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "\n",
    "\n",
    "            # if deployment_name in columns set dep=deployment_name, else split on basename\n",
    "            if 'deployment_name' in input_df.columns:\n",
    "                input_df['dep'] = input_df['deployment_name']\n",
    "            else:\n",
    "                input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "\n",
    "            # get the date from the filename\n",
    "            input_df['date'] = os.path.basename(c).split('.')[0].split('_')[-1]\n",
    "\n",
    "            # get the average number of detections per depoyment per night\n",
    "            input_df['avg_detections'] = input_df.groupby(['dep', 'date', 'order_name'])['image_path'].transform('count')\n",
    "\n",
    "\n",
    "            input_df['country'] = os.path.dirname(c).split('/')[-2].replace('_inferences_tracking', '')\n",
    "            df = input_df[['dep', 'date', 'order_name', 'country']].value_counts().reset_index()\n",
    "\n",
    "\n",
    "            # # if 'latitude' in input_df.columns:\n",
    "            # if 'latitude' not in input_df.columns:\n",
    "            #     input_df['latitude'] = 0\n",
    "            complete_df = pd.concat([complete_df, df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\" - Error processing {c}: {e}\")\n",
    "            continue\n",
    "        del input_df\n",
    "\n",
    "    complete_df = complete_df.reset_index(drop=True)\n",
    "    return complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f80717",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = activity_pop(inference_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each deployment get the average count\n",
    "activity_mean = activity_df.groupby(['date', 'order_name', 'country'])['count'].mean().reset_index()\n",
    "\n",
    "activity_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_mean['date'] = pd.to_datetime(activity_mean['date'], format='%Y-%m-%d')\n",
    "\n",
    "# get the rolling average of the count\n",
    "activity_mean['rolling_count_5'] = activity_mean.groupby(['order_name', 'country'])['count'].transform(lambda x: x.rolling(window=5, min_periods=1).mean())\n",
    "activity_mean['rolling_count_7'] = activity_mean.groupby(['order_name', 'country'])['count'].transform(lambda x: x.rolling(window=7, min_periods=1).mean())\n",
    "\n",
    "# Add day of year and month for seasonal analysis\n",
    "activity_mean['day_of_year'] = activity_mean['date'].dt.dayofyear\n",
    "\n",
    "# if year = 2025, add a year to day_of_year\n",
    "activity_mean.loc[activity_mean['date'].dt.year == 2025, 'day_of_year'] += 365\n",
    "\n",
    "activity_mean['month'] = activity_mean['date'].dt.month\n",
    "activity_mean['month_name'] = activity_mean['date'].dt.strftime('%b')\n",
    "\n",
    "# Check the data\n",
    "print(\"Date range:\", activity_mean['date'].min(), \"to\", activity_mean['date'].max())\n",
    "print(\"Countries:\", activity_mean['country'].unique())\n",
    "activity_mean.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4162736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seasonal activity plot - all countries on same plot with day of year as x-axis\n",
    "\n",
    "def plot_seasonal_activity_by_order(activity_df, column='count'):\n",
    "    df = activity_df.copy()\n",
    "\n",
    "    # sort by date\n",
    "    df = df.sort_values(by='date')\n",
    "    df.rename(columns={'order_name': 'Order'}, inplace=True)\n",
    "\n",
    "    # Set up beautiful color palette for countries\n",
    "    countries = sorted(df['country'].unique())\n",
    "    colors = sns.color_palette(\"husl\", n_colors=len(countries))  # Vibrant, distinct colors\n",
    "    country_colors = dict(zip(countries, colors))\n",
    "\n",
    "    # Apply colors to the palette\n",
    "    sns.set_palette([country_colors[country] for country in countries])\n",
    "\n",
    "    # Create the FacetGrid using day_of_year with enhanced styling\n",
    "    g = sns.FacetGrid(df, col='Order', hue='country', col_wrap=3, height=5, aspect=1.2,\n",
    "                      sharey=False, sharex=False, margin_titles=True)\n",
    "    g.map(sns.lineplot, 'day_of_year', column, linewidth=2.5, alpha=0.8, marker='o', markersize=4)\n",
    "\n",
    "    # Set labels and formatting for each subplot\n",
    "    for ax in g.axes.flat:\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Average Crops per Night', fontsize=11, fontweight='bold')\n",
    "\n",
    "        # Enhanced grid styling\n",
    "        ax.grid(True, alpha=0.4, linestyle='-', linewidth=0.5, color='lightgray')\n",
    "        ax.set_facecolor('#fafafa')  # Light background\n",
    "\n",
    "        # Style the subplot borders\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('darkgray')\n",
    "            spine.set_linewidth(1.5)\n",
    "\n",
    "        # Enhance subplot titles\n",
    "        title = ax.get_title()\n",
    "        if title:\n",
    "            # Extract order name and make it more readable\n",
    "            order_name = title.split(' = ')[-1] if ' = ' in title else title\n",
    "            ax.set_title(order_name.replace('_', ' ').title(),\n",
    "                        fontsize=12, fontweight='bold', pad=15, color='darkslategray')\n",
    "\n",
    "        # Add month labels on bottom with better styling\n",
    "        month_starts = [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]\n",
    "        month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "        # Add second year months if data spans multiple years\n",
    "        if ax.get_xlim()[1] > 365:\n",
    "            month_starts_year2 = [x + 365 for x in month_starts]\n",
    "            month_starts.extend(month_starts_year2)\n",
    "            month_labels.extend(month_labels)\n",
    "\n",
    "        xlim = ax.get_xlim()\n",
    "        visible_months = []\n",
    "        visible_labels = []\n",
    "\n",
    "        for month_day, label in zip(month_starts, month_labels):\n",
    "            if xlim[0] <= month_day <= xlim[1]:\n",
    "                visible_months.append(month_day)\n",
    "                visible_labels.append(label)\n",
    "\n",
    "        if visible_months:\n",
    "            ax.set_xticks(visible_months)\n",
    "            ax.set_xticklabels(visible_labels, fontsize=10, fontweight='bold')\n",
    "            ax.set_xlabel('Month', fontsize=11, fontweight='bold', color='darkslategray')\n",
    "\n",
    "        # Add year labels with enhanced styling\n",
    "        ax_year = ax.twiny()\n",
    "        ax_year.set_frame_on(False)\n",
    "        ax_year.xaxis.set_ticks_position('bottom')\n",
    "        ax_year.xaxis.set_label_position('bottom')\n",
    "        ax_year.spines['bottom'].set_position(('outward', 35))\n",
    "\n",
    "        subplot_data = df\n",
    "        if len(subplot_data) > 0:\n",
    "            years = sorted(subplot_data['date'].dt.year.unique())\n",
    "            year_positions = []\n",
    "            year_labels = []\n",
    "\n",
    "            for year in years:\n",
    "                if year == years[0]:\n",
    "                    year_pos = min(df['day_of_year'])\n",
    "                else:\n",
    "                    year_pos = 0 + (year - years[0]) * 365\n",
    "\n",
    "                if xlim[0] <= year_pos <= xlim[1]:\n",
    "                    year_positions.append(year_pos)\n",
    "                    year_labels.append(str(year))\n",
    "\n",
    "            if year_positions:\n",
    "                ax_year.set_xticks(year_positions)\n",
    "                ax_year.set_xticklabels(year_labels, fontsize=11, weight='bold', color='navy')\n",
    "                ax_year.set_xlim(xlim)\n",
    "                ax_year.set_xlabel('Year', fontsize=11, fontweight='bold', color='navy')\n",
    "\n",
    "    # Handle insufficient data with better styling\n",
    "    for ax in g.axes.flat:\n",
    "        if not ax.has_data():\n",
    "            ax.remove()\n",
    "        else:\n",
    "            order_name = ax.get_title().split(' = ')[-1] if ' = ' in ax.get_title() else ''\n",
    "            order_data = df[df['Order'] == order_name] if order_name else pd.DataFrame()\n",
    "\n",
    "            if len(order_data) < 5:\n",
    "                # Style for insufficient data\n",
    "                ax.set_facecolor('#f0f0f0')\n",
    "                ax.text(0.5, 0.5, f'Insufficient Data\\n({len(order_data)} observations)',\n",
    "                       transform=ax.transAxes, ha='center', va='center',\n",
    "                       fontsize=14, fontweight='bold', alpha=0.6, style='italic',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightcoral', alpha=0.3))\n",
    "\n",
    "                # Hide ticks but keep the styled background\n",
    "                ax.set_xticks([])\n",
    "                ax.set_xticklabels([])\n",
    "                ax.set_xlabel('')\n",
    "\n",
    "                # Hide year axis for insufficient data plots\n",
    "                for child_ax in ax.figure.axes:\n",
    "                    if hasattr(child_ax, 'get_shared_x_axes'):\n",
    "                        shared_axes = child_ax.get_shared_x_axes().get_siblings(ax)\n",
    "                        if child_ax in shared_axes and child_ax != ax:\n",
    "                            child_ax.set_xticks([])\n",
    "                            child_ax.set_xticklabels([])\n",
    "                            child_ax.set_xlabel('')\n",
    "\n",
    "    # Enhanced legend styling\n",
    "    g.add_legend(title='Country', bbox_to_anchor=(1.05, 1), loc='upper left',\n",
    "                borderaxespad=0., frameon=True, shadow=True, fancybox=True)\n",
    "\n",
    "    # Style the legend\n",
    "    legend = g._legend\n",
    "    if legend:\n",
    "        legend.set_title('Country', prop={'size': 12, 'weight': 'bold'})\n",
    "        legend.get_frame().set_facecolor('white')\n",
    "        legend.get_frame().set_alpha(0.9)\n",
    "        legend.get_frame().set_edgecolor('darkgray')\n",
    "        legend.get_frame().set_linewidth(1.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plt = plot_seasonal_activity_by_order(activity_mean)\n",
    "plt.suptitle('🦋 Seasonal Activity Patterns: Crops per Night by Country 🦋',\n",
    "             fontsize=20, fontweight='bold', y=0.98, color='darkslategray')\n",
    "plt.gcf().patch.set_facecolor('#f8f9fa')  # Light background for the figure\n",
    "plt.savefig(os.path.join(plot_dir, 'seasonal_activity_by_order_country.png'),\n",
    "            dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87249baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plt = plot_seasonal_activity_by_order(activity_mean, column='rolling_count_5')\n",
    "plt.suptitle('🦋 Seasonal Activity Patterns: 5-Night Rolling Average 🦋\\nSmoothed Trends Across Countries',\n",
    "             fontsize=18, fontweight='bold', y=0.98, color='darkslategray')\n",
    "plt.gcf().patch.set_facecolor('#f8f9fa')\n",
    "plt.savefig(os.path.join(plot_dir, 'rolling_seasonal_activity_by_order_country_5_night.png'),\n",
    "            dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plt = plot_seasonal_activity_by_order(activity_mean, column='rolling_count_7')\n",
    "plt.suptitle('🦋 Seasonal Activity Patterns: 7-Night Rolling Average 🦋\\nWeekly Trends Across Countries',\n",
    "             fontsize=18, fontweight='bold', y=0.98, color='darkslategray')\n",
    "plt.gcf().patch.set_facecolor('#f8f9fa')\n",
    "plt.savefig(os.path.join(plot_dir, 'rolling_seasonal_activity_by_order_country_7_night.png'),\n",
    "            dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750854f",
   "metadata": {},
   "source": [
    "# Activity by Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec30ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eaa5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e19f94b",
   "metadata": {},
   "source": [
    "# Total Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ecb780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all unique top_1_species in inference_csvs\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "unique_species = set()\n",
    "\n",
    "for c in tqdm(inference_csvs, desc='Extracting top_1_species'):\n",
    "    try:\n",
    "        df = pd.read_csv(c, usecols=['top_1_species'], low_memory=False, on_bad_lines='skip')\n",
    "        unique_species.update(df['top_1_species'].dropna().unique())\n",
    "    except Exception as e:\n",
    "        print(f\" - Error reading {c}: {e}\")\n",
    "\n",
    "unique_species = sorted(unique_species)\n",
    "print(f\"Found {len(unique_species)} unique top_1_species.\")\n",
    "unique_species[:20]  # Show first 20 as a preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8fe52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(unique_species)} unique top_1_species.\")\n",
    "# unique_species[:20]  # Show first 20 as a preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f6b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd4daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of unique top_*_species for all inference_csvs\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def analyze_all_top_species(inference_csvs):\n",
    "    \"\"\"\n",
    "    Analyze all top_*_species columns across all inference CSVs\n",
    "    Returns counts of unique species for each top_* column\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize sets for each top_species column\n",
    "    species_columns = ['top_1_species', 'top_2_species', 'top_3_species', 'top_4_species', 'top_5_species']\n",
    "    unique_species_dict = {col: set() for col in species_columns}\n",
    "\n",
    "    # Track which columns are actually present\n",
    "    available_columns = set()\n",
    "\n",
    "    for c in tqdm(inference_csvs, desc='Analyzing top_*_species across all CSVs'):\n",
    "        try:\n",
    "            # First check what columns are available in this CSV\n",
    "            df_sample = pd.read_csv(c, nrows=1, low_memory=False, on_bad_lines='skip')\n",
    "            file_columns = [col for col in species_columns if col in df_sample.columns]\n",
    "            available_columns.update(file_columns)\n",
    "\n",
    "            if not file_columns:\n",
    "                continue\n",
    "\n",
    "            # Read only the available species columns\n",
    "            df = pd.read_csv(c, usecols=file_columns, low_memory=False, on_bad_lines='skip')\n",
    "\n",
    "            # Add unique species from each column to respective sets\n",
    "            for col in file_columns:\n",
    "                if col in df.columns:\n",
    "                    unique_species_dict[col].update(df[col].dropna().unique())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" - Error reading {c}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Convert sets to sorted lists and count\n",
    "    results = {}\n",
    "    for col in species_columns:\n",
    "        if col in available_columns:\n",
    "            unique_list = sorted(unique_species_dict[col])\n",
    "            results[col] = {\n",
    "                'count': len(unique_list),\n",
    "                'species_list': unique_list\n",
    "            }\n",
    "        else:\n",
    "            results[col] = {\n",
    "                'count': 0,\n",
    "                'species_list': []\n",
    "            }\n",
    "\n",
    "    return results, available_columns\n",
    "\n",
    "# Run the analysis\n",
    "species_results, available_cols = analyze_all_top_species(inference_csvs)\n",
    "\n",
    "print(\"=== TOP SPECIES ANALYSIS SUMMARY ===\")\n",
    "print(f\"Available species columns: {sorted(available_cols)}\")\n",
    "print()\n",
    "\n",
    "for col in ['top_1_species', 'top_2_species', 'top_3_species', 'top_4_species', 'top_5_species']:\n",
    "    count = species_results[col]['count']\n",
    "    if count > 0:\n",
    "        print(f\"{col}: {count:,} unique species\")\n",
    "    else:\n",
    "        print(f\"{col}: Not available in CSV files\")\n",
    "\n",
    "print()\n",
    "print(\"=== DETAILED BREAKDOWN ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed results for each top_species column\n",
    "for col in ['top_1_species', 'top_2_species', 'top_3_species', 'top_4_species', 'top_5_species']:\n",
    "    if species_results[col]['count'] > 0:\n",
    "        print(f\"\\n--- {col.upper()} ---\")\n",
    "        print(f\"Total unique species: {species_results[col]['count']:,}\")\n",
    "\n",
    "        # Show first 10 and last 10 species as examples\n",
    "        species_list = species_results[col]['species_list']\n",
    "        if len(species_list) <= 20:\n",
    "            print(\"All species:\", species_list)\n",
    "        else:\n",
    "            print(\"First 10 species:\", species_list[:10])\n",
    "            print(\"Last 10 species:\", species_list[-10:])\n",
    "            print(\"... (middle species omitted) ...\")\n",
    "    else:\n",
    "        print(f\"\\n--- {col.upper()} ---\")\n",
    "        print(\"No data available\")\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "total_unique_across_all = set()\n",
    "for col in species_results:\n",
    "    total_unique_across_all.update(species_results[col]['species_list'])\n",
    "\n",
    "print(f\"Total unique species across ALL top_*_species columns: {len(total_unique_across_all):,}\")\n",
    "print(f\"Files processed: {len(inference_csvs)}\")\n",
    "print(f\"Available species ranking columns: {len(available_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparative analysis visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_species_count_comparison(species_results):\n",
    "    \"\"\"\n",
    "    Create a bar plot comparing unique species counts across top_*_species columns\n",
    "    \"\"\"\n",
    "    # Prepare data for plotting\n",
    "    columns = []\n",
    "    counts = []\n",
    "\n",
    "    for col in ['top_1_species', 'top_2_species', 'top_3_species', 'top_4_species', 'top_5_species']:\n",
    "        if species_results[col]['count'] > 0:\n",
    "            columns.append(col.replace('_', ' ').title())\n",
    "            counts.append(species_results[col]['count'])\n",
    "\n",
    "    if not columns:\n",
    "        print(\"No data available for plotting\")\n",
    "        return\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Use the existing color palette\n",
    "    bars = plt.bar(columns, counts, color=modern_palette[:len(columns)], alpha=0.8, edgecolor='darkgray', linewidth=1.5)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title('Number of Unique Species by Ranking Position\\nAcross All Inference CSV Files',\n",
    "              fontsize=16, fontweight='bold', color=web_colors['text'], pad=20)\n",
    "    plt.xlabel('Species Ranking Column', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Number of Unique Species', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01,\n",
    "                f'{count:,}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Format y-axis with commas\n",
    "    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))\n",
    "\n",
    "    # Style the plot\n",
    "    plt.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    plt.gca().set_facecolor(web_colors['background'])\n",
    "    sns.despine()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(plot_dir, 'unique_species_by_ranking.png'),\n",
    "                dpi=300, bbox_inches='tight', facecolor='white')\n",
    "\n",
    "# Create the visualization\n",
    "plot_species_count_comparison(species_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
