{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import json\n",
    "from boto3.s3.transfer import TransferConfig\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm, ListedColormap\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working directory\n",
    "os.chdir(os.path.expanduser('~/amber-inferences'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region='cri'\n",
    "country='costarica'\n",
    "download_dir=f'./data/qc_plots/{country}'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "inference_dir = os.path.abspath(f'/gws/nopw/j04/ceh_generic/kgoldmann/{country}_inferences_tracking/')\n",
    "\n",
    "#listdir recursively\n",
    "def listdir_recursive(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "\n",
    "# Get all csv files in the inference directory\n",
    "inference_csvs = list(listdir_recursive(inference_dir))\n",
    "inference_csvs = [c for c in inference_csvs if c.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inference_csvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and Data Wrangling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image(image_path, dir, df, ax, scaling_required=False, crop_to_highlight=None, buffer=5, subtitle=None):\n",
    "    df_image = df.loc[df['image_path'] == image_path, ]\n",
    "\n",
    "    img = plt.imread(f\"{dir}/{os.path.basename(image_path)}\")\n",
    "    image = Image.open(f\"{dir}/{os.path.basename(image_path)}\").convert(\"RGB\")\n",
    "    # subp = ax.imshow(img, origin='lower')\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for j, row in df_image.iterrows():\n",
    "        x_min = float(row['x_min']) -buffer\n",
    "        y_min = float(row['y_min']) -buffer\n",
    "        x_max = float(row['x_max']) +buffer\n",
    "        y_max = float(row['y_max']) +buffer\n",
    "\n",
    "        if scaling_required:\n",
    "            original_width, original_height = image.size\n",
    "            x_min = x_min /300 * original_width\n",
    "            y_min = y_min /300 * original_height\n",
    "            x_max = x_max /300 * original_width\n",
    "            y_max = y_max /300 * original_height\n",
    "\n",
    "        x = float(x_min)\n",
    "        y = float(y_min)\n",
    "        w = float(x_max - x_min)\n",
    "        h = float(y_max - y_min)\n",
    "\n",
    "        if (row['class_name'] == \"moth\") and ('Lepidoptera' not in row['order_name']):\n",
    "            col = 'orange'\n",
    "        elif (row['class_name'] != \"moth\") and ('Lepidoptera' in row['order_name']):\n",
    "            col = 'purple'\n",
    "        elif (row['class_name'] == \"moth\") and ('Lepidoptera' in row['order_name']):\n",
    "                col = 'green'\n",
    "        else:\n",
    "            col = 'red'\n",
    "\n",
    "        alph = 1\n",
    "        if crop_to_highlight is not None:\n",
    "            if row['crop_status'] != crop_to_highlight:\n",
    "                alph = 0.2\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"):\n",
    "                font_path = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
    "            else:\n",
    "                import cv2\n",
    "\n",
    "                font_path = os.path.join(\n",
    "                    cv2.__path__[0], \"qt\", \"fonts\", \"DejaVuSans.ttf\"\n",
    "                )\n",
    "            font = ImageFont.truetype(font_path, size=50)\n",
    "        except Exception as e:\n",
    "            print(f\"Loading default font, could not another: {e}\")\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "\n",
    "        if (row['class_name'] == \"moth\") or (\"Lepidoptera\" in row['order_name']):\n",
    "            draw.text(\n",
    "                (x_min, y_min),\n",
    "                f\"{row['top_1_species']}: {row['top_1_confidence']:.2f}\",\n",
    "                fill=col,\n",
    "                font=font,\n",
    "            )\n",
    "\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=col, width=3)\n",
    "\n",
    "        # rect = plt.Rectangle((x, y), w, h, fill=False, edgecolor=col, linewidth=1, alpha=alph)\n",
    "        # ax.add_patch(rect)\n",
    "\n",
    "    ax = plt.axes()\n",
    "\n",
    "    ax.add_patch(img)\n",
    "    if not subtitle:\n",
    "        subtitle=f\"{os.path.basename(image_path)}\"\n",
    "    ax.set_title(subtitle)\n",
    "    ax.axis('off')\n",
    "    # return subp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(s3_client, config, key, download_dir, bucket_name):\n",
    "    download_path = os.path.join(download_dir, os.path.basename(key))\n",
    "    s3_client.download_file(bucket_name, key, download_path, Config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_session(credentials_file=\"credentials.json\"):\n",
    "    \"\"\"\n",
    "    Load AWS and API credentials from a configuration file and initialise an AWS session.\n",
    "\n",
    "    Args:\n",
    "        credentials_file (str): Path to the credentials JSON file.\n",
    "\n",
    "    Returns:\n",
    "        boto3.Client: Initialised S3 client.\n",
    "    \"\"\"\n",
    "    with open(credentials_file, encoding=\"utf-8\") as config_file:\n",
    "        aws_credentials = json.load(config_file)\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=aws_credentials[\"AWS_ACCESS_KEY_ID\"],\n",
    "        aws_secret_access_key=aws_credentials[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "        region_name=aws_credentials[\"AWS_REGION\"],\n",
    "    )\n",
    "    client = session.client(\"s3\", endpoint_url=aws_credentials[\"AWS_URL_ENDPOINT\"])\n",
    "    return client\n",
    "\n",
    "client = initialise_session('./credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer configuration for optimised S3 download\n",
    "transfer_config = TransferConfig(\n",
    "    max_concurrency=20,  # Increase the number of concurrent transfers\n",
    "    multipart_threshold=8 * 1024 * 1024,  # 8MB\n",
    "    max_io_queue=1000,\n",
    "    io_chunksize=262144,  # 256KB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moth_only_df(inference_csvs):\n",
    "    df = pd.DataFrame()\n",
    "    for c in tqdm(inference_csvs, desc='Reading in the csvs'):\n",
    "        try:\n",
    "            input_df = pd.read_csv(c, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(f\" - Error reading {c}: {e}\")\n",
    "            continue\n",
    "        input_df = input_df.loc[input_df['crop_status'] != 'NO DETECTIONS FOR IMAGE', ]\n",
    "        input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "\n",
    "        input_df = input_df.loc[input_df['top_1_species'].isna() == False, ]\n",
    "        input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "        input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "\n",
    "        # set new keys column as 'dep' and 'image_path' combined\n",
    "        input_df['keys'] = input_df['image_path'].apply(lambda x: f\"{input_df['dep'].iloc[0]}/snapshot_images/{os.path.basename(x)}\")\n",
    "        df = pd.concat([df, input_df])\n",
    "        del input_df\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_summary(inference_csvs, category='order_name', macro_only=False):\n",
    "    df = pd.DataFrame()\n",
    "    for c in inference_csvs:\n",
    "        try:\n",
    "            input_df = pd.read_csv(c, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(f\" - Error reading {c}: {e}\")\n",
    "            continue\n",
    "        input_df = input_df.loc[input_df['crop_status'] != 'NO DETECTIONS FOR IMAGE', ]\n",
    "        input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "\n",
    "        input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "        input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "\n",
    "        if macro_only:\n",
    "            input_df = input_df.loc[input_df['class_name'] == 'Lepidoptera Macros', ]\n",
    "\n",
    "        # summarise the order_name by deployment\n",
    "        summary = input_df[['dep', category]].value_counts()\n",
    "        summary = summary.reset_index()\n",
    "        summary.columns = ['deployment', category, 'count']\n",
    "        summary['file'] = os.path.basename(c)\n",
    "\n",
    "        df = pd.concat([df, summary], ignore_index=True)\n",
    "        del input_df\n",
    "\n",
    "    df = df[['deployment', category, 'count']].groupby(['deployment', category]).sum().reset_index()\n",
    "\n",
    "    df = df.sort_values(by=['deployment', 'count'], ascending=[True, False])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(file_name, format=\"%Y-%m-%d\"):\n",
    "    \"\"\"\n",
    "    Extracts the date from the file name based on the specified format.\n",
    "    Assuming the date is in the filename and formatted as YYYYMMDD or similar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_name = os.path.splitext(file_name)[0]\n",
    "        file_raw = os.path.basename(file_name).replace(\"_\", \"-\").split(\"-\")\n",
    "        file = [x for x in file_raw if x.startswith(\"202\")][0]\n",
    "\n",
    "        # catch for delim between date and time in file name\n",
    "        if len(file) < 12:\n",
    "            i0 = [idx for idx in range(len(file_raw)) if file_raw[idx].startswith(\"202\")][0]\n",
    "            file = ('').join(file_raw[i0:i0+2])\n",
    "\n",
    "        image_dt = datetime.strptime(file, \"%Y%m%d%H%M%S%f\")\n",
    "        image_dt = datetime.strftime(image_dt, format)\n",
    "        return image_dt\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error parsing date from file name {file_name}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def assign_night(ts, night_endpoint=12, night_startpoint=12):\n",
    "    \"\"\"\n",
    "    Defines the recording night from date and time.\n",
    "    The recording night cutoff is defined between night_startpoint on day 1\n",
    "    and night_endpoint day 2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if ts.time() < time(night_endpoint, 0):  # before night_endpoint o'clock\n",
    "            night_start = ts.date() - timedelta(days=1)\n",
    "        elif ts.time() >= time(night_startpoint, 0):  # after night_startpoint or later\n",
    "            night_start = ts.date()\n",
    "        else:\n",
    "            # times not included in this overnight window\n",
    "            night_start = pd.NaT\n",
    "        if pd.isna(night_start):\n",
    "            return None\n",
    "        night_end = night_start + timedelta(days=1)\n",
    "        return night_start\n",
    "    except Exception as e:\n",
    "        return 'No known date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_plot_data(df, drop_empty_days = True, min_date=pd.to_datetime('2024-01-01'), end_date=None):\n",
    "    df['session'] = pd.to_datetime(df['session'])\n",
    "\n",
    "    if end_date is None:\n",
    "        end_date = df['session'].max()\n",
    "\n",
    "    all_dates = pd.date_range(start=min_date, end=end_date)\n",
    "    df = df.set_index('session').fillna(0).reindex(all_dates).rename_axis('session').reset_index()\n",
    "\n",
    "    # Add week, day of week, and year\n",
    "    df['week'] = df['session'].dt.isocalendar().week\n",
    "    df['weekday'] = df['session'].dt.weekday  # Monday=0\n",
    "    df['month'] = df['session'].dt.month\n",
    "    df['year'] = df['session'].dt.year\n",
    "    df['week_number'] = ((df['session'] - min_date).dt.days // 7).astype(int)\n",
    "    df['week_label'] = 'W' + df['week_number'].astype(str)\n",
    "\n",
    "    # Some dates in last week of December may belong to week 1 of next year\n",
    "    df.loc[df['week'] == 1, 'year'] = df['session'].dt.year\n",
    "\n",
    "    # Pivot for heatmap\n",
    "    heatmap_data = df.pivot_table(index='weekday', columns='week_number', values='count', aggfunc='sum')\n",
    "\n",
    "    # Reorder to GitHub style\n",
    "    day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    heatmap_data.index = [day_names[i] for i in heatmap_data.index]\n",
    "    heatmap_data = heatmap_data.reindex(['Sun', 'Sat', 'Fri', 'Thu', 'Wed', 'Tue', 'Mon'])\n",
    "\n",
    "    # Determine month and year labels\n",
    "    unique_weeks = df.drop_duplicates('week_number')\n",
    "    month_labels = unique_weeks.set_index('week_number').loc[heatmap_data.columns, 'session'].dt.strftime('%b')\n",
    "    week_labels = unique_weeks.set_index('week_number').loc[heatmap_data.columns, 'week_label']\n",
    "    year_labels = unique_weeks.set_index('week_number').loc[heatmap_data.columns, 'year']\n",
    "\n",
    "\n",
    "    if drop_empty_days:\n",
    "        heatmap_data = heatmap_data.fillna(0)\n",
    "        heatmap_data = heatmap_data.loc[(heatmap_data != 0).any(axis=1)]\n",
    "        heatmap_data = heatmap_data.dropna(axis=0, how='all')\n",
    "\n",
    "    return [heatmap_data, month_labels, week_labels, year_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_plot(df,\n",
    "                  ax,\n",
    "                  dep,\n",
    "                  min_date=pd.to_datetime('2024-01-01'),\n",
    "                  vmin=0,\n",
    "                  vmax=1e6,\n",
    "                  custom_cmap='Greens',\n",
    "                  include_month_labels=True,\n",
    "                  end_date=None,\n",
    "                  label_buffer=1,\n",
    "                  show_colourbar=True,\n",
    "                  drop_empty_days=True\n",
    "    ):\n",
    "\n",
    "    heatmap_data, month_labels, week_labels, year_labels = activity_plot_data(df, drop_empty_days=drop_empty_days, min_date=min_date, end_date=end_date)\n",
    "    masked_data = np.ma.masked_invalid(heatmap_data.values)\n",
    "\n",
    "    norm = LogNorm(vmin=vmin, vmax=vmax + 1)\n",
    "\n",
    "    c = ax.pcolor(masked_data, cmap=custom_cmap,\n",
    "                  edgecolors='white', linewidths=1, norm=norm)\n",
    "\n",
    "    ax.set_yticks(np.arange(0.5, len(heatmap_data.index), 1))\n",
    "    ax.set_yticklabels(heatmap_data.index)\n",
    "\n",
    "    ax.set_xticks(np.arange(0.5, len(week_labels), 1))\n",
    "    ax.set_xticklabels(week_labels, rotation=90)\n",
    "\n",
    "    if include_month_labels:\n",
    "        for i, label in enumerate(month_labels):\n",
    "            if i > 0 and month_labels[i] != month_labels[i - 1]:\n",
    "                ax.text(i + 0.5, -2*label_buffer, label, ha='center', va='center')\n",
    "            elif i == 0:\n",
    "                ax.text(i + 0.5, -2*label_buffer, label, ha='center', va='center')\n",
    "\n",
    "        for i, label in enumerate(year_labels):\n",
    "            if i > 0 and year_labels[i] != year_labels[i - 1]:\n",
    "                ax.text(i + 0.5, -3*label_buffer, label, ha='center', va='center')\n",
    "            elif i == 0:\n",
    "                ax.text(i + 0.5, -3*label_buffer, label, ha='center', va='center')\n",
    "\n",
    "    if show_colourbar:\n",
    "        fig.colorbar(c, ax=ax, orientation='vertical', label='Number of crops')\n",
    "    ax.set_title(dep)\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Activity Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df for deployment counts\n",
    "dep_session = pd.DataFrame()\n",
    "dep_session_moth = pd.DataFrame()\n",
    "dep_hour = pd.DataFrame()\n",
    "for c in tqdm(inference_csvs, desc='reading in the csvs'):\n",
    "    try:\n",
    "        input_df = pd.read_csv(c, low_memory=False)\n",
    "    except Exception as e:\n",
    "        print(f\" - Error reading {c}: {e}\")\n",
    "        continue\n",
    "    input_df = input_df.loc[input_df['crop_status'] != 'NO DETECTIONS FOR IMAGE', ]\n",
    "    input_df = input_df.loc[input_df['crop_status'] != 'No detections for this image.', ]\n",
    "    input_df = input_df.loc[input_df['crop_status'] != 'Image corrupt', ]\n",
    "\n",
    "    if input_df.shape[0] == 0:\n",
    "        print(f\"  - No detections in {os.path.basename(c)}\")\n",
    "        continue\n",
    "    input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "\n",
    "    input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "    input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "    input_df['datetime'] = input_df['image_path'].apply(lambda x: get_date(x, format=\"%Y-%m-%d %H:%M:%S\"))\n",
    "    input_df['datetime'] = pd.to_datetime(input_df['datetime'])\n",
    "    input_df['hour'] = input_df['datetime'].dt.hour\n",
    "\n",
    "    # get the session night\n",
    "    input_df['session'] = input_df['datetime'].apply(assign_night)\n",
    "\n",
    "    # summarise the order_name by deployment\n",
    "    summary = input_df[['dep', 'session']].value_counts()\n",
    "    summary = summary.reset_index()\n",
    "    summary['file'] = os.path.basename(c)\n",
    "    dep_session = pd.concat([dep_session, summary], ignore_index=True)\n",
    "\n",
    "    summary = input_df[['dep', 'hour', 'order_name']].value_counts()\n",
    "    summary = summary.reset_index()\n",
    "    summary['file'] = os.path.basename(c)\n",
    "    dep_hour = pd.concat([dep_hour, summary], ignore_index=True)\n",
    "\n",
    "    # summarise the order_name by deployment\n",
    "    input_df = input_df.loc[input_df['order_name'].isna() == False, ]\n",
    "    try:\n",
    "        input_df = input_df.loc[input_df['order_name'].str.contains(\"Lepidoptera\"), ]\n",
    "        summary_moth = input_df[['dep', 'session']].value_counts()\n",
    "        summary_moth = summary_moth.reset_index()\n",
    "        summary_moth['file'] = os.path.basename(c)\n",
    "        dep_session_moth = pd.concat([dep_session_moth, summary_moth], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error processing moths in {c}: {e}\")\n",
    "\n",
    "    del input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployments = dep_session['dep'].unique()\n",
    "print(deployments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_hour_df = dep_hour[['dep', 'count', 'hour', 'order_name']].groupby(['dep', 'hour', 'order_name']).mean().reset_index()\n",
    "dep_hour_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_session_df = dep_session.loc[dep_session['session'] != 'No known date', ]\n",
    "dep_session_df = dep_session_df[['dep', 'count', 'session']].groupby(['dep', 'session']).mean().reset_index()\n",
    "dep_session_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_session_all_moth = dep_session_moth.loc[dep_session_moth['session'] != 'No known date', ]\n",
    "dep_session_all_moth = dep_session_all_moth[['count', 'session']].groupby(['session']).mean().reset_index()\n",
    "dep_session_all_moth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_session_df_moth = dep_session_moth.loc[dep_session_moth['session'] != 'No known date', ]\n",
    "dep_session_df_moth = dep_session_df_moth[['dep', 'count', 'session']].groupby(['dep', 'session']).mean().reset_index()\n",
    "dep_session_df_moth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_df = dep_session_df[['dep', 'count']].groupby(['dep']).mean().reset_index()\n",
    "dep_df = dep_df.sort_values(by=['dep', 'count'], ascending=[True, False])\n",
    "dep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_session_df_all = dep_session_df[['session', 'count']].groupby(['session']).mean().reset_index()\n",
    "dep_session_df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github style activity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.Greens\n",
    "newcolors = cmap(np.linspace(0, 1, 256))\n",
    "newcolors[0] = [1, 1, 1, 1]  # RGBA for white\n",
    "custom_cmap = ListedColormap(newcolors)\n",
    "custom_cmap.set_bad(color=(0.85, 0.85, 0.85, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "activity_plot(dep_session_df_all, ax, dep='All', min_date=pd.to_datetime('2024-01-01'),\n",
    "              vmin=1, vmax=dep_session_df_all['count'].max(), custom_cmap=custom_cmap, label_buffer=1.5)\n",
    "\n",
    "ax.set_title(\"Crop Activity Heatmap\")\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date=pd.to_datetime('2024-01-01')\n",
    "max_labels = ((pd.to_datetime(dep_session_df['session']).max() - min_date).days // 7)\n",
    "date_range = pd.date_range(start=min_date, end=pd.to_datetime(dep_session_df['session']).max(), freq='W')\n",
    "\n",
    "week_labels = ['W' + str(i+1) for i in range(len(date_range))]\n",
    "year_labels = [x.strftime('%Y') for x in date_range]\n",
    "month_labels = [x.strftime('%b') for x in date_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots with activity plots for each deployment\n",
    "ncols=1\n",
    "nrows=int(math.ceil(len(deployments)/ncols))\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(20, 25), sharex='all')\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, dep in enumerate(deployments):\n",
    "    c=activity_plot(\n",
    "        dep_session_df.loc[dep_session_df['dep'] == dep, ['dep', 'session', 'count']],\n",
    "        axs[i], dep=dep, min_date=pd.to_datetime('2024-01-01'),\n",
    "        vmin=1, vmax=dep_session_df['count'].max(), label_buffer=2,\n",
    "        custom_cmap=custom_cmap, drop_empty_days=False, include_month_labels=False,\n",
    "        end_date = dep_session_df['session'].max(), show_colourbar=False\n",
    "    )\n",
    "    axs[i].set_aspect('equal')\n",
    "\n",
    "axs[i].set_xticks(np.arange(0.5, len(week_labels), 1))\n",
    "axs[i].set_xticklabels(week_labels, rotation=90)\n",
    "axs[i-1].set_xticks(np.arange(0.5, len(week_labels), 1))\n",
    "axs[i-1].set_xticklabels(week_labels, rotation=90)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.25, -0.1*ncols, 0.5, 0.03])  # [left, bottom, width, height]\n",
    "fig.colorbar(c, cax=cbar_ax, orientation='horizontal', label='Crop count (log scale)')\n",
    "\n",
    "# Optional week index labels\n",
    "for i, label in enumerate(month_labels):\n",
    "    if i > 0 and month_labels[i] != month_labels[i - 1]:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -2*ncols, label, ha='center', va='center')\n",
    "    elif i == 0:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -2*ncols, label, ha='center', va='center')\n",
    "\n",
    "\n",
    "for i, label in enumerate(year_labels):\n",
    "    if i > 0 and year_labels[i] != year_labels[i - 1]:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -3*ncols, label, ha='center', va='center')\n",
    "    elif i == 0:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -3*ncols, label, ha='center', va='center')\n",
    "\n",
    "plt.suptitle(\"Crop Activity Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.Purples\n",
    "newcolors = cmap(np.linspace(0, 1, 256))\n",
    "newcolors[0] = [1, 1, 1, 1]  # RGBA for white\n",
    "custom_cmap = ListedColormap(newcolors)\n",
    "custom_cmap.set_bad(color=(0.85, 0.85, 0.85, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_session_moth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "activity_plot(dep_session_all_moth, ax, dep='All', min_date=pd.to_datetime('2024-01-01'),\n",
    "              vmin=1, vmax=dep_session_all_moth['count'].max(), custom_cmap=custom_cmap, label_buffer=1.5)\n",
    "\n",
    "ax.set_title(\"Crop Activity Heatmap\")\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots with activity plots for each deployment\n",
    "ncols=1\n",
    "nrows=int(math.ceil(len(deployments)/ncols))\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(20, 25), sharex='all')\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, dep in enumerate(dep_df['dep'].unique()):\n",
    "    c=activity_plot(dep_session_df_moth.loc[dep_session_df_moth['dep'] == dep, ['dep', 'session', 'count']],\n",
    "                  axs[i], dep=dep, min_date=pd.to_datetime('2024-01-01'),\n",
    "                vmin=1, vmax=dep_session_df_moth['count'].max(), label_buffer=2,\n",
    "                custom_cmap=custom_cmap, include_month_labels=False,\n",
    "                end_date = pd.to_datetime(dep_session_df_moth['session']).max(),\n",
    "                    drop_empty_days=False,\n",
    "                show_colourbar=False)\n",
    "    axs[i].set_aspect('equal')\n",
    "\n",
    "axs[i].set_xticks(np.arange(0.5, len(week_labels), 1))\n",
    "axs[i].set_xticklabels(week_labels, rotation=90)\n",
    "axs[i-1].set_xticks(np.arange(0.5, len(week_labels), 1))\n",
    "axs[i-1].set_xticklabels(week_labels, rotation=90)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.25, -0.1*ncols, 0.5, 0.03])  # [left, bottom, width, height]\n",
    "fig.colorbar(c, cax=cbar_ax, orientation='horizontal', label='Crop count (log scale)')\n",
    "\n",
    "# Optional week index labels\n",
    "for i, label in enumerate(month_labels):\n",
    "    if i > 0 and month_labels[i] != month_labels[i - 1]:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -2*ncols, label, ha='center', va='center')\n",
    "    elif i == 0:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -2*ncols, label, ha='center', va='center')\n",
    "\n",
    "\n",
    "for i, label in enumerate(year_labels):\n",
    "    if i > 0 and year_labels[i] != year_labels[i - 1]:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -3*ncols, label, ha='center', va='center')\n",
    "    elif i == 0:\n",
    "        for j in range(1, ncols+1):\n",
    "            axs[len(dep_df['dep'].unique())-j].text(i + 0.5, -3*ncols, label, ha='center', va='center')\n",
    "\n",
    "plt.suptitle(\"Moth Crop Activity Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Polar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_hour_df_all = dep_hour_df[['hour', 'order_name', 'count']].groupby(['hour', 'order_name']).mean().reset_index()\n",
    "dep_hour_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_names = dep_hour_df_all['order_name'].unique()\n",
    "palette = sns.color_palette(\"tab20\", len(order_names))\n",
    "order_colors = dict(zip(order_names, palette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "\n",
    "for order, group in dep_hour_df_all.groupby('order_name'):\n",
    "    df_loop = pd.concat([group, group.iloc[[0]]]).reset_index(drop=True)\n",
    "\n",
    "    # add a discontinuity between the first and last point\n",
    "    if any(df_loop['hour'] < 12):\n",
    "        end_of_session = df_loop.loc[df_loop['hour'] < 12, 'hour'].max()\n",
    "        end_of_session_index = df_loop.loc[df_loop['hour'] == end_of_session].index[0]\n",
    "        extra_row = pd.DataFrame({'hour': end_of_session, 'count': [np.nan], 'order_name': [order]})\n",
    "\n",
    "        # add a row after the end_of_session hour\n",
    "        if end_of_session_index < len(df_loop) - 1:\n",
    "            next_hour = df_loop.loc[end_of_session_index + 1, 'hour']\n",
    "            df_loop = pd.concat([df_loop.iloc[:end_of_session_index + 1], extra_row, df_loop.iloc[end_of_session_index + 1:]], ignore_index=True)\n",
    "        else:\n",
    "            df_loop = pd.concat([df_loop, extra_row], ignore_index=True)\n",
    "\n",
    "    theta = np.deg2rad(df_loop['hour'] * 15)  # 24h clock mapped to 360°\n",
    "    ax.plot(theta, df_loop['count'], label=order, color=order_colors[order])\n",
    "\n",
    "ax.set_theta_direction(-1)\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_xticks(np.linspace(0, 2 * np.pi, 24, endpoint=False))\n",
    "ax.set_xticklabels([f\"{h}:00\" for h in range(24)])\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# move legend to the right, outside the plot\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.2, 1), title='Order Name')\n",
    "plt.title('Average Insect Activity by Hour of Day\\n\\n')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots with activity plots for each deployment\n",
    "ncols=2\n",
    "nrows=int(math.ceil(len(deployments)/ncols))\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(10, 15), sharex='all', subplot_kw={'projection': 'polar'})\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, dep in enumerate(dep_df['dep'].unique()):\n",
    "    df = dep_hour_df.loc[dep_hour_df['dep'] == dep, ]\n",
    "    for order, group in df.groupby('order_name'):\n",
    "        df_loop = pd.concat([group, group.iloc[[0]]]).reset_index(drop=True)\n",
    "\n",
    "        # after the maximum hour under 12, add a discontinuity\n",
    "        if any(df_loop['hour'] < 12):\n",
    "            end_of_session = df_loop.loc[df_loop['hour'] < 12, 'hour'].max()\n",
    "            end_of_session_index = df_loop.loc[df_loop['hour'] == end_of_session].index[0]\n",
    "            extra_row = pd.DataFrame({'dep': dep, 'hour': end_of_session, 'count': [np.nan], 'order_name': [order]})\n",
    "\n",
    "            # add a row after the end_of_session hour\n",
    "            if end_of_session_index < len(df_loop) - 1:\n",
    "                # get the next hour\n",
    "                next_hour = df_loop.loc[end_of_session_index + 1, 'hour']\n",
    "                df_loop = pd.concat([df_loop.iloc[:end_of_session_index + 1], extra_row, df_loop.iloc[end_of_session_index + 1:]], ignore_index=True)\n",
    "            else:\n",
    "                df_loop = pd.concat([df_loop, extra_row], ignore_index=True)\n",
    "\n",
    "        theta = np.deg2rad(df_loop['hour'] * 15)  # 24h clock mapped to 360°\n",
    "        axs[i].plot(theta, df_loop['count'], label=order, color=order_colors[order])\n",
    "\n",
    "    axs[i].set_theta_direction(-1)\n",
    "    axs[i].set_theta_offset(np.pi / 2)\n",
    "    axs[i].set_xticks(np.linspace(0, 2 * np.pi, 24, endpoint=False))\n",
    "    axs[i].set_xticklabels([f\"{h}:00\" for h in range(24)])\n",
    "    axs[i].set_yscale('log')\n",
    "    axs[i].set_title(f'{dep}\\n\\n')\n",
    "\n",
    "# Build a single legend using the shared color map\n",
    "handles = [plt.Line2D([0], [0], color=color, label=order) for order, color in order_colors.items()]\n",
    "fig.legend(handles=handles, title='Order Name', loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.07))\n",
    "\n",
    "plt.suptitle('Average Insect Activity by Hour of Day\\n\\n')\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.subplots_adjust(top=0.93)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Last hour not reflective number since this could be midway between hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots with activity plots for each deployment\n",
    "ncols=3\n",
    "nrows=int(math.ceil(len(deployments)/ncols))\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, dep in enumerate(dep_df['dep'].unique()):\n",
    "    df = dep_hour_df.loc[dep_hour_df['dep'] == dep, ]\n",
    "    # If the hour is < 12 then add 24 to the hour\n",
    "    df.loc[df['hour'] < 12, 'hour'] = df.loc[df['hour'] < 12, 'hour'] +24 # df['hour'].apply(lambda x: x + 24 if x < 12 else x)\n",
    "\n",
    "    for order, group in df.groupby('order_name'):\n",
    "        group = group.sort_values('hour')\n",
    "        axs[i].plot(group['hour'], group['count'], label=order, color=order_colors[order])\n",
    "    axs[i].set_yscale('log')\n",
    "    axs[i].set_title(f'{dep}')\n",
    "    axs[i].set_ylabel('Count (log scale)')\n",
    "    axs[i].set_xlabel('Hour of Day')\n",
    "\n",
    "    min_hour = df['hour'].min()\n",
    "    max_hour = df['hour'].max()\n",
    "    times_raw = np.arange(16, 4+24 + 1, 1)\n",
    "    times_labels = [x - 24 if x > 24 else x for x in times_raw]\n",
    "    times_labels = [f\"{int(x)}:00\" for x in times_labels]\n",
    "    axs[i].set_xticks(times_raw)\n",
    "    axs[i].set_xlim(16, 4+24+1)\n",
    "    axs[i].set_xticklabels(times_labels, rotation=-45, ha='left')\n",
    "\n",
    "\n",
    "# Build a single legend using the shared color map\n",
    "handles = [plt.Line2D([0], [0], color=color, label=order) for order, color in order_colors.items()]\n",
    "fig.legend(handles=handles, title='Order Name', loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.2))\n",
    "\n",
    "plt.suptitle('Insect Activity by Hour of Day\\n\\n')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.93)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Crop counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=dep_df, hue='count', y='count', x='dep')\n",
    "plt.title('All crops per deployment')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.yscale('log')\n",
    "plt.legend().set_visible(False)\n",
    "plt.ylabel('Average Nightly Number of crops')\n",
    "plt.xlabel('Deployment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moth Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = moth_only_df(inference_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_path'].value_counts().plot(kind='hist', bins=100, figsize=(5, 3))\n",
    "plt.title('Moth crops per image')\n",
    "plt.xlabel('Number of moth crops per image (n > 0)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dep'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the confidence distribution for each deployment in subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 5), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, dep in enumerate(df['dep'].unique()):\n",
    "    ax = axes[i]\n",
    "    dep_df = df.loc[df['dep'] == dep, ]\n",
    "    dep_df['image_path'].value_counts().plot(kind='hist', bins=100, ax=ax)\n",
    "    ax.set_title(dep)\n",
    "    ax.set_xlabel('Number of moth crops per image (n > 0)')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "plt.suptitle(f'Confidence Distribution of 5 Most Likely Species Predictions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_counts = df['dep'].value_counts()\n",
    "dep_counts = dep_counts.reset_index()\n",
    "dep_counts.columns = ['deployment', 'count']\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=dep_counts, hue='count', y='count', x='deployment')\n",
    "plt.title('Moth crops per deployment')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.yscale('log')\n",
    "# plt.legend(visible=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Prediction Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot showing the correlation between order confidence and crop area\n",
    "# this plot takes a while to compile, uncomment if you want to run\n",
    "# sns.regplot(x=df['order_confidence'], y=df['crop_area'], logx=True, line_kws=dict(color=\"r\"))\n",
    "# plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_counts = cat_summary(inference_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=order_counts, hue='deployment', y='count', x='order_name')\n",
    "plt.title('Counts by Deployment and Order')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Order')\n",
    "plt.ylabel('Number of Crops')\n",
    "plt.legend(title='Order Name', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species Prediction Plots (Macro only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_counts = cat_summary(inference_csvs, category='top_1_species', macro_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only the top 10 species\n",
    "top_species = species_counts[['top_1_species', 'order_name', 'count']].groupby('top_1_species').sum().reset_index()\n",
    "top_species = top_species.sort_values(by='count', ascending=False)\n",
    "top_species = top_species.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match the order_name fromd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=top_species, y='count', x='top_1_species')\n",
    "plt.title('Top Species Counts')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Most Likely Species')\n",
    "plt.ylabel('Number of Crops')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_species.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_counts['deployment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 7), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, dep in enumerate(species_counts['deployment'].unique()):\n",
    "    ax = axes[i]\n",
    "    dep_df = species_counts.loc[species_counts['deployment'] == dep, ]\n",
    "    dep_df = dep_df.sort_values(by='count', ascending=False).head(10)\n",
    "    sns.barplot(data=dep_df, y='count', x='top_1_species', ax=ax)\n",
    "    ax.set_title(dep)\n",
    "    ax.set_xticks(range(len(dep_df)))\n",
    "    ax.set_xticklabels(dep_df['top_1_species'], rotation=45, ha='right')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Number of Crops')\n",
    "\n",
    "plt.suptitle('Top Species Observations by Deployment')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(data=species_counts.loc[species_counts['top_1_species'].isin(top_species['top_1_species']), ], hue='deployment', y='count', x='top_1_species')\n",
    "plt.title('Top Species Counts by Deployment')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Most popular species', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Most Likely Species')\n",
    "plt.ylabel('Number of Crops')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['top_1_confidence'].plot(kind='hist', bins=50, figsize=(6, 3))\n",
    "df['top_2_confidence'].plot(kind='hist', bins=50, color='orange', alpha=0.5)\n",
    "df['top_3_confidence'].plot(kind='hist', bins=50, color='yellow', alpha=0.5)\n",
    "df['top_4_confidence'].plot(kind='hist', bins=50, color='green', alpha=0.5)\n",
    "df['top_5_confidence'].plot(kind='hist', bins=50, color='purple', alpha=0.5)\n",
    "\n",
    "plt.legend(['Top 1 Confidence', 'Top 2 Confidence', 'Top 3 Confidence', 'Top 4 Confidence', 'Top 5 Confidence'])\n",
    "plt.title('Confidence Distribution of 5 Most Likely Species Predictions')\n",
    "plt.xlabel('Confidence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the confidence distribution for each deployment in subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 5), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, dep in enumerate(df['dep'].unique()):\n",
    "    ax = axes[i]\n",
    "    dep_df = df.loc[df['dep'] == dep, ]\n",
    "    dep_df['top_1_confidence'].plot(kind='hist', bins=50, ax=ax, alpha=0.5)\n",
    "    dep_df['top_2_confidence'].plot(kind='hist', bins=50, ax=ax, color='orange', alpha=0.5)\n",
    "    dep_df['top_3_confidence'].plot(kind='hist', bins=50, ax=ax, color='yellow', alpha=0.5)\n",
    "    dep_df['top_4_confidence'].plot(kind='hist', bins=50, ax=ax, color='green', alpha=0.5)\n",
    "    dep_df['top_5_confidence'].plot(kind='hist', bins=50, ax=ax, color='purple', alpha=0.5)\n",
    "    ax.legend().set_visible(False)\n",
    "    ax.set_title(dep)\n",
    "    ax.set_xlabel('Confidence')\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "\n",
    "handles, _ = axes[0].get_legend_handles_labels()\n",
    "labels = ['Top 1 Confidence', 'Top 2 Confidence', 'Top 3 Confidence', 'Top 4 Confidence', 'Top 5 Confidence']\n",
    "fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.2, 0.9))\n",
    "plt.suptitle(f'Confidence Distribution of 5 Most Likely Species Predictions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Confident cases for each order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_from_file(inference_csvs, sort_by='top_1_confidence', ascending=False, n_keep=100, group_by_col=None, remove_none=True):\n",
    "    \"\"\"\n",
    "    Load the dataframe from the CSV file and sort it by the specified column and keep the top n entries (with an optional group by).\n",
    "\n",
    "    Args:\n",
    "        inference_csvs (list): List of CSV file paths to read.\n",
    "        sort_by (str): The column name to sort by.\n",
    "        ascending (bool): Whether to sort in ascending order.\n",
    "        n_keep (int): The number of entries to keep from each file.\n",
    "        group_by_col (str): The column name to group by before keeping the top n entries.\n",
    "        remove_none (bool): Whether to remove entries with 'NO DETECTIONS FOR IMAGE'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The sorted dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for c in tqdm(inference_csvs):\n",
    "        try:\n",
    "            input_df = pd.read_csv(c, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(f\" - Error reading {c}: {e}\")\n",
    "        continue\n",
    "        if remove_none:\n",
    "            input_df = input_df.loc[input_df['crop_status'] != 'NO DETECTIONS FOR IMAGE', ]\n",
    "        input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "        input_df = input_df.sort_values(by=sort_by, ascending=ascending)\n",
    "\n",
    "        input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "        input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "\n",
    "        # set new keys column as 'dep' and 'image_path' combined\n",
    "        input_df['keys'] = input_df['image_path'].apply(lambda x: f\"{input_df['dep'].iloc[0]}/snapshot_images/{os.path.basename(x)}\")\n",
    "\n",
    "        if group_by_col is not None:\n",
    "            input_df = input_df.groupby(group_by_col).head(n_keep)\n",
    "        else:\n",
    "            input_df = input_df.head(n_keep)\n",
    "        df = pd.concat([df, input_df])\n",
    "        del input_df\n",
    "\n",
    "    df = df.sort_values(by=['dep', sort_by], ascending=[True, ascending]).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df = load_df_from_file(inference_csvs, sort_by='order_confidence', ascending=False, n_keep=100, remove_none=True, group_by_col='order_name')\n",
    "\n",
    "# get *the* most confident image for each order and deployment\n",
    "order_df = order_df.groupby(['order_name', 'dep']).head(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of images required per order\n",
    "# n_images = 1\n",
    "\n",
    "# # create a df for the most confidence order predictions\n",
    "# order_df = pd.DataFrame()\n",
    "# for c in tqdm(inference_csvs):\n",
    "#     input_df = pd.read_csv(c, low_memory=False)\n",
    "#     input_df = input_df.loc[input_df['crop_status'] != 'NO DETECTIONS FOR IMAGE', ]\n",
    "#     input_df = input_df.drop_duplicates(subset=[ 'x_min', 'x_max', 'y_min', 'y_max'])\n",
    "#     input_df = input_df.sort_values(by='order_confidence', ascending=False)\n",
    "\n",
    "#     input_df['dep'] = os.path.basename(c).split('.')[0].split('_')[0]\n",
    "#     input_df['crop_area'] = (input_df['x_max'] - input_df['x_min']) * (input_df['y_max'] - input_df['y_min'])\n",
    "\n",
    "#     # set new keys column as 'dep' and 'image_path' combined\n",
    "#     input_df['keys'] = input_df['image_path'].apply(lambda x: f\"{input_df['dep'].iloc[0]}/snapshot_images/{os.path.basename(x)}\")\n",
    "#     order_df = pd.concat([order_df, input_df])\n",
    "#     del input_df\n",
    "\n",
    "# order_df = order_df.sort_values(by=['dep', 'order_confidence'], ascending=[True, False])\n",
    "# order_df = order_df.groupby(['order_name', 'dep']).head(n_images).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by confidence and subset\n",
    "df_order = order_df.sort_values(by='order_confidence', ascending=False)\n",
    "df_order = df_order.loc[df_order['order_confidence'] > 0.99, ]\n",
    "df_order.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df_order.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'order'), exist_ok=True)\n",
    "\n",
    "for i, row in df_order.iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'order'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw, Image, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image(image_path, dir, df, ax, scaling_required=False, crop_to_highlight=None, buffer=5, subtitle=None):\n",
    "    df_image = df.loc[df['image_path'] == image_path, ]\n",
    "\n",
    "    img = plt.imread(f\"{dir}/{os.path.basename(image_path)}\")\n",
    "    image = Image.open(f\"{dir}/{os.path.basename(image_path)}\").convert(\"RGB\")\n",
    "    # subp = ax.imshow(img, origin='lower')\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for j, row in df_image.iterrows():\n",
    "        x_min = float(row['x_min']) -buffer\n",
    "        y_min = float(row['y_min']) -buffer\n",
    "        x_max = float(row['x_max']) +buffer\n",
    "        y_max = float(row['y_max']) +buffer\n",
    "\n",
    "        if scaling_required:\n",
    "            original_width, original_height = image.size\n",
    "            x_min = x_min /300 * original_width\n",
    "            y_min = y_min /300 * original_height\n",
    "            x_max = x_max /300 * original_width\n",
    "            y_max = y_max /300 * original_height\n",
    "\n",
    "        x = float(x_min)\n",
    "        y = float(y_min)\n",
    "        w = float(x_max - x_min)\n",
    "        h = float(y_max - y_min)\n",
    "\n",
    "        if (row['class_name'] == \"moth\") and ('Lepidoptera' not in row['order_name']):\n",
    "            col = 'orange'\n",
    "        elif (row['class_name'] != \"moth\") and ('Lepidoptera' in row['order_name']):\n",
    "            col = 'purple'\n",
    "        elif (row['class_name'] == \"moth\") and ('Lepidoptera' in row['order_name']):\n",
    "                col = 'green'\n",
    "        else:\n",
    "            col = 'red'\n",
    "\n",
    "        alph = 1\n",
    "        if crop_to_highlight is not None:\n",
    "            if row['crop_status'] != crop_to_highlight:\n",
    "                alph = 0.2\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"):\n",
    "                font_path = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
    "            else:\n",
    "                import cv2\n",
    "\n",
    "                font_path = os.path.join(\n",
    "                    cv2.__path__[0], \"qt\", \"fonts\", \"DejaVuSans.ttf\"\n",
    "                )\n",
    "            font = ImageFont.truetype(font_path, size=50)\n",
    "        except Exception as e:\n",
    "            print(f\"Loading default font, could not another: {e}\")\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "\n",
    "        if (row['class_name'] == \"moth\") or (\"Lepidoptera\" in row['order_name']):\n",
    "            draw.text(\n",
    "                (x_min, y_min),\n",
    "                f\"{row['top_1_species']}: {row['top_1_confidence']:.2f}\",\n",
    "                fill=col,\n",
    "                font=font,\n",
    "            )\n",
    "\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=col, width=3)\n",
    "\n",
    "        # rect = plt.Rectangle((x, y), w, h, fill=False, edgecolor=col, linewidth=1, alpha=alph)\n",
    "        # ax.add_patch(rect)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(13, 3, figsize=(10, 17))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_order = df_order.sort_values(by='order_name', ascending=False)\n",
    "\n",
    "# Use enumerate to get the correct loop index for ax[]\n",
    "for j, (_, row) in enumerate(df_order.iterrows()):\n",
    "    annotate_image2(\n",
    "        image_path=row['image_path'],\n",
    "        dir=os.path.join(download_dir, 'order'),\n",
    "        df=df_order,\n",
    "        ax=ax[j],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"{row['dep']}\\n{row['order_name']}, {row['order_confidence']:.2f}\"\n",
    "    )\n",
    "\n",
    "# Turn off any unused axes\n",
    "for i in range(len(df_order), len(ax)):\n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 17))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "df_order = df_order.sort_values(by='order_name', ascending=False)\n",
    "\n",
    "# Use enumerate to get the correct loop index for ax[]\n",
    "for j, (_, row) in enumerate(df_order.iloc[-4:-3, ].iterrows()):\n",
    "    annotate_image2(\n",
    "        image_path=row['image_path'],\n",
    "        dir=os.path.join(download_dir, 'order'),\n",
    "        df=df_order,\n",
    "        ax=ax,\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"{row['dep']}\\n{row['order_name']}, {row['order_confidence']:.2f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Confident Species Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confident = load_df_from_file(inference_csvs, sort_by='top_1_confidence', ascending=False, n_keep=10, remove_none=True, group_by_col='top_1_species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by top_1_confidence\n",
    "# df_confident = df.sort_values(by='top_1_confidence', ascending=False)\n",
    "# df_confident.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # remove duplicated rows by image path, and bounding box\n",
    "# df_confident = df_confident.drop_duplicates(subset=['image_path', 'x_min', 'y_min', 'x_max', 'y_max'])\n",
    "# df_confident = df_confident.drop_duplicates(subset=['top_1_species'])\n",
    "\n",
    "top_n=20\n",
    "\n",
    "df_confident = df_confident.head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by image_path\n",
    "df_confident.sort_values(by='image_path', inplace=True)\n",
    "df_confident.reset_index(drop=True, inplace=True)\n",
    "df_confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confident.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'confident'), exist_ok=True)\n",
    "\n",
    "for i, row in df_confident.head(top_n).iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'confident'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confident.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image2(image_path, dir, df, ax, scaling_required=False, crop_to_highlight=None, buffer=5, subtitle=None):\n",
    "    df_image = df.loc[df['image_path'] == image_path, ]\n",
    "\n",
    "    img = plt.imread(f\"{dir}/{os.path.basename(image_path)}\")\n",
    "    image = Image.open(f\"{dir}/{os.path.basename(image_path)}\").convert(\"RGB\")\n",
    "    subp = ax.imshow(img, origin='lower')\n",
    "\n",
    "    for j, row in df_image.iterrows():\n",
    "        x_min = row['x_min'] -buffer\n",
    "        y_min = row['y_min'] -buffer\n",
    "        x_max = row['x_max'] +buffer\n",
    "        y_max = row['y_max'] +buffer\n",
    "\n",
    "        if scaling_required:\n",
    "            original_width, original_height = image.size\n",
    "            x_min = x_min *300 / original_width\n",
    "            y_min = y_min *300 / original_height\n",
    "            x_max = x_max *300 / original_width\n",
    "            y_max = y_max *300 / original_height\n",
    "\n",
    "        x = int(x_min)\n",
    "        y = int(y_min)\n",
    "        w = int(x_max - x_min)\n",
    "        h = int(y_max - y_min)\n",
    "\n",
    "        if (row['class_name'] == \"moth\") and ('Lepidoptera' not in row['order_name']):\n",
    "            col = 'orange'\n",
    "        elif (row['class_name'] != \"moth\") and ('Lepidoptera' in row['order_name']):\n",
    "            col = 'purple'\n",
    "        elif (row['class_name'] == \"moth\") and ('Lepidoptera' in row['order_name']):\n",
    "                col = 'green'\n",
    "        else:\n",
    "            col = 'red'\n",
    "\n",
    "        alph = 1\n",
    "        if crop_to_highlight is not None:\n",
    "            if row['crop_status'] != crop_to_highlight:\n",
    "                alph = 0.2\n",
    "\n",
    "\n",
    "        if (row['class_name'] == \"moth\") or (\"Lepidoptera\" in row['order_name']):\n",
    "            ax.text(x_min, y_max,\n",
    "                    f\"{row['top_1_species']}: {row['top_1_confidence']:.2f}\",\n",
    "                    color=col,\n",
    "                    fontsize=5, alpha=alph,\n",
    "                    verticalalignment=\"bottom\")\n",
    "\n",
    "        rect = plt.Rectangle((x, y), w, h, fill=False, edgecolor=col, linewidth=1, alpha=alph)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    if not subtitle:\n",
    "        subtitle=f\"{os.path.basename(image_path)}\"\n",
    "    ax.set_title(subtitle)\n",
    "    ax.axis('off')\n",
    "    return subp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(4, 5, figsize=(13.33, 7.5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_confident = df_confident.sort_values(by='top_1_confidence', ascending=False)\n",
    "\n",
    "# for eah row in df_confident, get the image_path\n",
    "for i, row in df_confident.iterrows():\n",
    "    annotate_image2(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'confident'),\n",
    "        df_confident,\n",
    "        ax[i],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=True,\n",
    "        subtitle=f\"{row['dep']}\\n{row['top_1_species']}, {row['top_1_confidence']:.2f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "for i in range(len(df_confident), len(ax)):\n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Largest Moths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area = load_df_from_file(inference_csvs, sort_by='crop_area', ascending=False, n_keep=10, remove_none=True, group_by_col='order_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by moth size\n",
    "df_area = df_area.sort_values(by='crop_area', ascending=False)\n",
    "df_area.reset_index(drop=True, inplace=True)\n",
    "# df_area = df_area.drop_duplicates(subset=['top_1_species'])\n",
    "# df_area = df_area.loc[df_area['top_1_confidence'] > 0.85, ]\n",
    "df_area = df_area.loc[df_area['order_name'] != 'Lepidoptera Macros', ]\n",
    "df_area = df_area.loc[df_area['order_name'] != 'Lepidoptera Micros', ]\n",
    "\n",
    "top_n=20\n",
    "\n",
    "df_area = df_area.head(top_n)\n",
    "\n",
    "df_area.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'largest'), exist_ok=True)\n",
    "\n",
    "for i, row in df_area.iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'largest'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area['order_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(4, 5, figsize=(13.33, 7.5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_area = df_area.sort_values(by='crop_area', ascending=False)\n",
    "\n",
    "# for eah row in df_confident, get the image_path\n",
    "for i, row in df_area.iterrows():\n",
    "    annotate_image2(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'largest'),\n",
    "        df_area,\n",
    "        ax[i],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"{row['top_1_species']}, ({row['top_1_confidence']:.2f})\"\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(13.33, 7.5))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "df_area = df_area.sort_values(by='crop_area', ascending=False)\n",
    "\n",
    "# for eah row in df_confident, get the image_path\n",
    "for i, row in df_area.iloc[1:2, ].iterrows():\n",
    "    annotate_image2(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'largest'),\n",
    "        df_area,\n",
    "        ax,\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"{row['top_1_species']}, ({row['top_1_confidence']:.2f})\"\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blurriest Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by moth size\n",
    "df_blur = df.sort_values(by='crop_bluriness', ascending=False)\n",
    "df_blur.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_blur = df_blur.drop_duplicates(subset=['top_1_species'])\n",
    "top_n=20\n",
    "\n",
    "df_blur = df_blur.head(top_n)\n",
    "\n",
    "df_blur.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'blur'), exist_ok=True)\n",
    "\n",
    "for i, row in df_blur.iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'blur'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(4, 5, figsize=(13.33, 7.5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_blur = df_blur.sort_values(by='crop_bluriness', ascending=False)\n",
    "\n",
    "# for eah row in df_blur, get the image_path\n",
    "for i, row in df_blur.iterrows():\n",
    "    annotate_image(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'blur'),\n",
    "        df_blur,\n",
    "        ax[i],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"Crop blur: {float(row['crop_bluriness']):.3f}\\nImage blur: {float(row['image_bluriness']):.3f}\"\n",
    "\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bluriest Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by moth size\n",
    "df = df.astype({'image_bluriness': 'float'})\n",
    "df_blur = df.sort_values(by='image_bluriness', ascending=False)\n",
    "\n",
    "df_blur.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_blur = df_blur.drop_duplicates(subset=['top_1_species'])\n",
    "df_blur = df_blur.drop_duplicates(subset=['image_bluriness'])\n",
    "top_n=20\n",
    "\n",
    "df_blur = df_blur.head(top_n)\n",
    "\n",
    "df_blur.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the relevant images\n",
    "os.makedirs(os.path.join(download_dir, 'blur'), exist_ok=True)\n",
    "\n",
    "for i, row in df_blur.iterrows():\n",
    "    download_images(client, transfer_config, row['keys'], os.path.join(download_dir, 'blur'), region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique image, annotate the bounding box\n",
    "fig, ax = plt.subplots(4, 5, figsize=(13.33, 7.5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df_blur = df_blur.sort_values(by='crop_bluriness', ascending=False)\n",
    "\n",
    "# for eah row in df_blur, get the image_path\n",
    "for i, row in df_blur.iterrows():\n",
    "    annotate_image(\n",
    "        row['image_path'],\n",
    "        os.path.join(download_dir, 'blur'),\n",
    "        df_blur,\n",
    "        ax[i],\n",
    "        crop_to_highlight=row['crop_status'],\n",
    "        buffer=20,\n",
    "        scaling_required=False,\n",
    "        subtitle=f\"Crop blur: {float(row['crop_bluriness']):.3f}\\nImage blur: {float(row['image_bluriness']):.3f}\"\n",
    "\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_file = '/home/users/katriona/amber-inferences/keys/thailand_final/dep000074.json'\n",
    "\n",
    "with open(json_file, \"r\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "\n",
    "# create a dataframe from the json file as filename column\n",
    "df_json = pd.DataFrame(chunks, columns=['filename'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json['datetime'] = df_json['filename'].apply(lambda x: x.split('/')[2].replace('-snapshot.jpg', '') )\n",
    "df_json['datetime'] = pd.to_datetime(df_json['datetime'], format='%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the time is < 12, add 24 hours to the date\n",
    "df_json['session'] = df_json['datetime']\n",
    "df_json['session'] = df_json['datetime'].apply(lambda x: x - pd.Timedelta(days=1) if x.hour < 12 else x)\n",
    "df_json['session'] = df_json['session'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(df_json['session'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a dict grouped by session\n",
    "sessions = df_json.groupby('session')['filename'].apply(list).to_dict()\n",
    "\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions['2024-07-24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/gws/nopw/j04/ceh_generic/kgoldmann/costarica_inferences_tracking/dep000031/dep000031_2024-06-03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "\n",
    "df = df.loc[df['crop_status'] != 'No detections for this image.', ]\n",
    "\n",
    "# drop nan\n",
    "df = df.loc[df['best_match_crop'].notna(), ]\n",
    "df = df.loc[df['total_cost'].notna(), ]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_match_crop'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of total cost\n",
    "df['total_cost'] = df['total_cost'].astype(float)\n",
    "df['total_cost'].plot(kind='hist', bins=50, figsize=(10, 5))\n",
    "plt.title('Total Cost Distribution')\n",
    "plt.xlabel('Total Cost')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_id_calc2(best_matches, cost_threshold=1, col_palette='tab20'):\n",
    "        # Make a copy and rename the relevant columns\n",
    "    best_matches = best_matches.copy()\n",
    "\n",
    "    best_matches = best_matches.loc[best_matches['total_cost'] != \"\", ]\n",
    "    best_matches['image1'] = [os.path.basename(x) for x in best_matches['image_path']]\n",
    "    best_matches['image2'] = best_matches['previous_image']\n",
    "    best_matches['crop1'] = best_matches['crop_status']\n",
    "    best_matches['crop2'] = best_matches['best_match_crop']\n",
    "\n",
    "    # Filter based on the cost threshold\n",
    "    filtered_matches = best_matches[best_matches[\"total_cost\"] < cost_threshold]\n",
    "\n",
    "    def node_id(image_path, crop_id):\n",
    "        return f\"{image_path}|{crop_id}\"\n",
    "\n",
    "    # Build a graph of matches under the threshold\n",
    "    G_thresh = nx.Graph()\n",
    "    for _, row in filtered_matches.iterrows():\n",
    "        n1 = node_id(row['image1'], row['crop1'])\n",
    "        n2 = node_id(row['image2'], row['crop2'])\n",
    "        G_thresh.add_edge(n1, n2)\n",
    "\n",
    "    # Assign track IDs from connected components\n",
    "    track_mapping = {}\n",
    "    for tid, component in enumerate(nx.connected_components(G_thresh)):\n",
    "        for node in component:\n",
    "            track_mapping[node] = f\"Track_{str(tid).rjust(5, '0')}\"\n",
    "\n",
    "    # Collect all unique nodes from both sides\n",
    "    all_nodes = set()\n",
    "    for _, row in best_matches.iterrows():\n",
    "        all_nodes.add(node_id(row['image1'], row['crop1']))\n",
    "        all_nodes.add(node_id(row['image2'], row['crop2']))\n",
    "\n",
    "    # Create lookup for cost (minimum per crop node)\n",
    "    cost_lookup = {}\n",
    "    for _, row in best_matches.iterrows():\n",
    "        for prefix in [\"1\", \"2\"]:\n",
    "            nid = node_id(row[f\"image{prefix}\"], row[f\"crop{prefix}\"])\n",
    "            cost = row[\"total_cost\"]\n",
    "            cost_lookup[nid] = min(cost_lookup.get(nid, float(\"inf\")), cost)\n",
    "\n",
    "    # Assemble the final output rows\n",
    "    output_rows = []\n",
    "    for node in all_nodes:\n",
    "        image_path, crop_id = node.rsplit(\"|\", 2)\n",
    "        output_rows.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"crop_id\": crop_id,\n",
    "            \"track_id\": track_mapping.get(node),  # May be None if unmatched under threshold\n",
    "            \"total_cost\": cost_lookup.get(node)\n",
    "        })\n",
    "\n",
    "    output_df = pd.DataFrame(output_rows)\n",
    "\n",
    "    # Assign unique track IDs to unmatched crops\n",
    "    max_existing_id = (\n",
    "        max(\n",
    "            [int(tid.replace(\"Track_\", \"\")) for tid in output_df[\"track_id\"].dropna()],\n",
    "            default=-1\n",
    "        )\n",
    "    )\n",
    "    unmatched_mask = output_df[\"track_id\"].isnull()\n",
    "    unmatched_indices = output_df[unmatched_mask].index\n",
    "    new_ids = [\n",
    "        f\"Track_{str(i).rjust(5, '0')}\"\n",
    "        for i in range(max_existing_id + 1, max_existing_id + 1 + unmatched_mask.sum())\n",
    "    ]\n",
    "    output_df.loc[unmatched_indices, \"track_id\"] = new_ids\n",
    "\n",
    "\n",
    "    # create a colour label\n",
    "    # Generate N unique colors for each track\n",
    "    num_tracks = output_df['track_id'].nunique()\n",
    "\n",
    "    # Use a colormap to get visually distinct colors\n",
    "    cmap = plt.cm.get_cmap(col_palette, num_tracks)  # tab20\n",
    "\n",
    "    # Map track_id to hex colors\n",
    "    track_id_to_color = {\n",
    "        track_id: mcolors.to_hex(cmap(i)) for i, track_id in enumerate(sorted(output_df['track_id'].unique()))\n",
    "    }\n",
    "\n",
    "    # Add color column to DataFrame\n",
    "    output_df['colour'] = output_df['track_id'].map(track_id_to_color)\n",
    "\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = track_id_calc2(df, cost_threshold=1, col_palette='tab20')\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df['track_id'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_path_basename'] = df['image_path'].apply(lambda x: os.path.basename(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(output_df, how='left', left_on=['image_path_basename', 'crop_status'], right_on=['image_path', 'crop_id'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.columns.str.contains('_y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with '_y' suffix\n",
    "df = df.loc[:, ~df.columns.str.contains('_y')]\n",
    "# rename columns with '_x' suffix to remove it\n",
    "df = df.rename(columns=lambda x: x.replace('_x', ''))\n",
    "\n",
    "# drop the colour column\n",
    "df = df.drop(columns=['colour'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df\n",
    "output_file = './dep000031_2024-06-03_tracked.csv'\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of snapshots per crop:\n",
    "pd.DataFrame(df['track_id'].value_counts())['count'].value_counts().plot(kind='bar', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['track_id'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to the 3 most common track IDs\n",
    "top_tracks = df['track_id'].value_counts().head(3).index.tolist()\n",
    "df = df.loc[df['track_id'] == 'Track_00119', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['track_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = 'dep000031/snapshot_images/' + df['image_path_basename'].unique()\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(keys)):\n",
    "    try:\n",
    "        download_images(client, transfer_config, keys[i], '/gws/nopw/j04/ceh_generic/kgoldmann/test', 'cri',)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {keys[i]}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.loc[df['image_path_basename'].isin(os.listdir('/gws/nopw/j04/ceh_generic/kgoldmann/test')), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unique track_ids\n",
    "frame_cutoff = 1\n",
    "\n",
    "track_counts = df_sub[\"track_id\"].value_counts()\n",
    "valid_tracks = track_counts[track_counts > frame_cutoff].index\n",
    "df_sub = df_sub[df_sub[\"track_id\"].isin(valid_tracks)].reset_index(drop=True)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amber_inferences.utils.plotting import *\n",
    "from amber_inferences.utils.tracking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['image_path_basename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "for i, image_path in enumerate(df_sub['image_path_basename'].unique()):\n",
    "    image_path_full = f'/gws/nopw/j04/ceh_generic/kgoldmann/test/{image_path}'\n",
    "    imge = Image.open(image_path_full).convert(\"RGB\")\n",
    "    original_image = imge.copy()\n",
    "    original_width, original_height = imge.size\n",
    "\n",
    "    crops_df = df_sub.loc[df_sub['image_path_basename'] == os.path.basename(image_path_full), ]\n",
    "    boxes = []\n",
    "    if crops_df.shape[0] > 0:\n",
    "        for j, row in crops_df.iterrows():\n",
    "            boxes.append({\n",
    "                'x_min': row['x_min'],\n",
    "                'y_min': row['y_min'],\n",
    "                'x_max': row['x_max'],\n",
    "                'y_max': row['y_max'],\n",
    "                'label': row['track_id'],\n",
    "                'ann_col': 'black' #row['colour']\n",
    "            })\n",
    "\n",
    "    im = image_annotation(image_path_full, boxes=boxes, scale=False)\n",
    "    out_path = f'/gws/nopw/j04/ceh_generic/kgoldmann/ann_test/{os.path.basename(image_path_full)}'\n",
    "    im.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
