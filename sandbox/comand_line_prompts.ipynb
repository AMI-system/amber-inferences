{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86bec42",
   "metadata": {},
   "source": [
    "# Running the Pipeline from Command Line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f472cad",
   "metadata": {},
   "source": [
    "The entire pipeline can be run from the command line. The commands are shown below for demonstrative purposes using subprocess, but for high throughput analysis we recommend using slurm. There are examples of slurm scripts in the ./slurm_scripts directory: each regional bash file (e.g. `costarica_final.sh`) calls on the sbatch file `array_processor.sh`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280cdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the wd\n",
    "import os\n",
    "os.chdir(os.path.expanduser('~/amber-inferences'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa44b7e-c3e5-4e8d-9ec0-1b53d360c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4dc9a-7e58-435a-8b77-dcce96c138c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from amber_inferences.utils.config import load_credentials\n",
    "# from amber_inferences.utils.api_utils import deployments_summary, get_deployments\n",
    "# from amber_inferences.utils.custom_models import *\n",
    "# from amber_inferences.utils.inference_scripts import *\n",
    "# from amber_inferences.utils.plotting import *\n",
    "# from amber_inferences.utils.tracking import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path as syspath\n",
    "from os import path as ospath\n",
    "\n",
    "syspath.append('/home/users/katriona/amber-inferences')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a815a8f2",
   "metadata": {},
   "source": [
    "## Inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c91973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "chunk_id = 1\n",
    "batch_size = 20 # runs for 20 images at a time\n",
    "\n",
    "country='costarica'\n",
    "region=\"cri\"\n",
    "\n",
    "credentials_file=\"./credentials.json\"\n",
    "\n",
    "deployment_id = \"dep000035\"\n",
    "output_base_dir=f\"./data/{deployment_id}/{country}_test\"\n",
    "json_file = f\"./examples/example_keys/test.json\" #interesting_timelapse.json\"\n",
    "\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "os.makedirs(f\"{output_base_dir}/{deployment_id}\", exist_ok=True)\n",
    "\n",
    "species_model=\"./models/turing-costarica_v03_resnet50_2024-06-04-16-17_state.pt\"\n",
    "species_labels=\"./models/03_costarica_data_category_map.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b719669",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_number_padded = f\"{chunk_id:04d}\"\n",
    "csv_file = f\"{output_base_dir}/{deployment_id}_{batch_number_padded}.csv\"\n",
    "# json_file = csv_file.replace('csv', 'json')\n",
    "print(f\"Results will save to {csv_file}\")\n",
    "# print(f\"Embeddings will save to {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983fcb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ospath.exists(csv_file):\n",
    "    os.remove(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0437bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = [\n",
    "    \"python3\", \"-m\",\n",
    "    \"amber_inferences.cli.perform_inferences\",\n",
    "    \"--chunk_id\", str(chunk_id),\n",
    "    \"--batch_size\", str(batch_size),\n",
    "    \"--json_file\", json_file,\n",
    "    \"--output_dir\", output_base_dir,\n",
    "    \"--bucket_name\", region,\n",
    "    \"--credentials_file\", credentials_file,\n",
    "    \"--csv_file\", csv_file,\n",
    "    \"--species_model_path\", species_model,\n",
    "    \"--species_labels\", species_labels,\n",
    "    \"--perform_inference\",\n",
    "    \"--remove_image\",\n",
    "    \"--box_threshold\", \"0\",\n",
    "    \"--binary_model_path\", \"./models/moth-nonmoth-effv2b3_20220506_061527_30.pth\",\n",
    "    \"--localisation_model_path\", \"./models/v1_localizmodel_2021-08-17-12-06.pt\",\n",
    "    \"--order_model_path\", \"./models/dhc_best_128.pth\",\n",
    "    \"--order_thresholds_path\", \"./models/thresholdsTestTrain.csv\",\n",
    "    \"--skip_processed\",\n",
    "    \"--verbose\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(command, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.stdout)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"STDERR:\\n\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060efa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41622b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918da39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629afbb9-f0c5-406b-b348-3bd723912ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'python3 -m amber_inferences.cli.perform_inferences \\\n",
    "    --chunk_id {str(chunk_id)} \\\n",
    "    --batch_size {str(batch_size)} \\\n",
    "    --json_file {json_file} \\\n",
    "    --output_dir {output_base_dir} \\\n",
    "    --bucket_name {region} \\\n",
    "    --credentials_file {credentials_file} \\\n",
    "    --csv_file {csv_file} \\\n",
    "    --species_model_path {species_model} \\\n",
    "    --species_labels {species_labels} \\\n",
    "    --perform_inference \\\n",
    "    --remove_image \\\n",
    "    --box_threshold \"0\" \\\n",
    "    --binary_model_path \"./models/moth-nonmoth-effv2b3_20220506_061527_30.pth\" \\\n",
    "    --localisation_model_path \"./models/flat_bug_M.pt\" \\\n",
    "    --order_model_path \"./models/dhc_best_128.pth\" \\\n",
    "    --order_thresholds_path \"./models/thresholdsTestTrain.csv\" \\\n",
    "    --skip_processed \\\n",
    "    --verbose')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa911f",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from amber_inferences.utils.tracking import *\n",
    "import os\n",
    "os.chdir(os.path.expanduser('~/amber-inferences'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8579fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('./data/dep000035/costarica_test/dep000035_0001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec92420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the json file\n",
    "batch_json = './data/dep000035/costarica_test/dep000035_0001.json'\n",
    "with open(batch_json, encoding=\"utf-8\") as file:\n",
    "    embedding_list = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ebce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list[list(embedding_list.keys())[0]]['crop_1']['image_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_similarities = crop_costs(embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6df597",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929cd2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_matches = find_best_matches(crop_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb90e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = track_id_calc(best_matches, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359daeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedddadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Generate N unique colors for each track\n",
    "num_tracks = tracks_df['track_id'].nunique()\n",
    "\n",
    "# Use a colormap to get visually distinct colors\n",
    "cmap = plt.cm.get_cmap('hsv', num_tracks)  # tab20\n",
    "\n",
    "# Map track_id to hex colors\n",
    "track_id_to_color = {\n",
    "    track_id: mcolors.to_hex(cmap(i)) for i, track_id in enumerate(sorted(tracks_df['track_id'].unique()))\n",
    "}\n",
    "\n",
    "# Add color column to DataFrame\n",
    "tracks_df['colour'] = tracks_df['track_id'].map(track_id_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00732007",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crops_merge = results_df.merge(tracks_df, how='left', left_on=['image_path', 'crop_status'], right_on=['image_path', 'crop_id'])\n",
    "all_crops_merge = all_crops_merge.reset_index(drop=True)\n",
    "all_crops_merge.sort_values('track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_raw = image_paths = os.listdir('./examples/images/dep000035/interesting_timelapse/raw/')\n",
    "image_paths_raw = [os.path.abspath(os.path.join('./examples/images/dep000035/interesting_timelapse/raw/', x)) for x in image_paths_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24771dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176244b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crops_merge_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bbe7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "# drop unique track_ids\n",
    "all_crops_merge_subset = all_crops_merge.copy()\n",
    "track_counts = all_crops_merge_subset[\"track_id\"].value_counts()\n",
    "valid_tracks = track_counts[track_counts > 1].index\n",
    "all_crops_merge_subset = all_crops_merge_subset[all_crops_merge_subset[\"track_id\"].isin(valid_tracks)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "for i, image_path in enumerate(image_paths_raw):\n",
    "    imge = Image.open(image_path).convert(\"RGB\")\n",
    "    original_image = imge.copy()\n",
    "    original_width, original_height = imge.size\n",
    "\n",
    "    crops_df = all_crops_merge_subset.loc[\n",
    "    all_crops_merge_subset['image_path'] == f'./data/dep000035/costarica_test/{os.path.basename(image_path)}', ]\n",
    "    print(crops_df)\n",
    "    crops_df = crops_df.loc[crops_df['crop_status'] != 'NO DETECTIONS FOR IMAGE',]\n",
    "    crops_df = crops_df.loc[crops_df['track_id'].notna(),]\n",
    "\n",
    "    boxes = []\n",
    "    if crops_df.shape[0] > 0:\n",
    "        for j, row in crops_df.iterrows():\n",
    "\n",
    "            boxes.append({\n",
    "                'x_min': row['x_min'],\n",
    "                'y_min': row['y_min'],\n",
    "                'x_max': row['x_max'],\n",
    "                'y_max': row['y_max'],\n",
    "                'label': row['track_id'],\n",
    "                'ann_col': row['colour']\n",
    "            })\n",
    "\n",
    "\n",
    "    im = image_annotation(image_path, boxes=boxes, scale=False)\n",
    "    out_path = f'{output_dir}/{os.path.basename(image_path)}'\n",
    "    im.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open images and convert to a sequence\n",
    "image_paths = os.listdir(output_dir)\n",
    "image_paths = [os.path.join(output_dir, x) for x in image_paths]\n",
    "images = [Image.open(img) for img in image_paths]\n",
    "\n",
    "# Save as GIF\n",
    "gif_path = \"./examples/images/dep000035/interesting_timelapse/gifs/test_tracking_images.gif\"\n",
    "images[0].save(gif_path, save_all=True, append_images=images[1:], duration=500, loop=0)\n",
    "\n",
    "del images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\"![trackingGif](\" + os.path.abspath(gif_path) + \" 'tracking')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc58f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
